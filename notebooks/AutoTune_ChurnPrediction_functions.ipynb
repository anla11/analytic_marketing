{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drive test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone -b propensity_prediction 'https://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@github.com/primedata-ai/ds.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install auto-sklearn==0.12.5\n",
    "# !pip install torch==1.7.0\n",
    "# !pip install pyro-ppl==1.4.0\n",
    "# !pip install lifelines==0.24.16\n",
    "# !pip install scikit-learn==0.22.2\n",
    "# !pip install pandas==1.0.5\n",
    "# !pip install seaborn==0.10.1\n",
    "# !pip install xlrd==1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# JSON_CONFIG_PATH = '/content/drive/My Drive/Colab Notebooks/PrimeDataAI/data_examples/config.json'\n",
    "# f = open(JSON_CONFIG_PATH, 'r')\n",
    "# global_config = json.load(f)\n",
    "# data_path = '/content/drive/My Drive/Colab Notebooks/PrimeDataAI/data_examples/NKI_cleaned.csv'\n",
    "# global_config['data_config']['path'] = data_path\n",
    "# global_config.keys(), global_config.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnbuB1LYpF06"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hLdvBfI3er50"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8LY4EDVXioOP",
    "outputId": "654b272e-8ace-4173-89f7-efa6ffcdb567"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['tasks', 'data_config']),\n",
       " dict_values(['churn_prediction', {'path': '../data/NKI_cleaned/NKI_cleaned.csv', 'History': {'user_id': 'ID', 'user_seniority': 'timerecurrence', 'event': 'eventdeath', 'metadata': {'Patient': 'id', 'age': 'numeric', 'survival': 'numeric', 'chemo': 'numeric', 'hormonal': 'numeric', 'amputation': 'numeric', 'histtype': 'numeric', 'diam': 'numeric', 'posnodes': 'numeric', 'grade': 'numeric', 'angioinv': 'numeric', 'lymphinfil': 'numeric', 'barcode': 'numeric', 'esr1': 'numeric', 'G3PDH_570': 'numeric', 'Contig45645_RC': 'numeric', 'Contig44916_RC': 'numeric', 'D25272': 'numeric', 'J00129': 'numeric', 'Contig29982_RC': 'numeric', 'Contig56678_RC': 'numeric', 'Contig53047_RC': 'numeric', 'Contig19551': 'numeric', 'Contig47230_RC': 'numeric', 'Contig46501_RC': 'numeric', 'Contig20749_RC': 'numeric', 'AL157500': 'numeric', 'AL157502': 'numeric', 'Contig37376_RC': 'numeric', 'Contig45395_RC': 'numeric', 'X98307': 'numeric', 'AL157505': 'numeric', 'AB033027': 'numeric', 'Contig24026_RC': 'numeric', 'Contig27800_RC': 'numeric', 'Contig42500_RC': 'numeric', 'Contig7147': 'numeric', 'Contig32037_RC': 'numeric', 'Contig16374_RC': 'numeric', 'Contig42349_RC': 'numeric', 'Contig33976_RC': 'numeric', 'Contig49874_RC': 'numeric', 'AB033060': 'numeric', 'U45975': 'numeric', 'M34428': 'numeric', 'AB033083': 'numeric', 'NM_003004': 'numeric', 'Contig7192': 'numeric', 'Contig23039_RC': 'numeric', 'Contig22685_RC': 'numeric', 'D84140': 'numeric', 'Contig43806_RC': 'numeric', 'NM_003022': 'numeric', 'Contig54847_RC': 'numeric', 'Contig33260_RC': 'numeric', 'NM_002300': 'numeric', 'Contig13929_RC': 'numeric', 'NM_002318': 'numeric', 'NM_003058': 'numeric', 'Contig66143_RC': 'numeric', 'Contig44519_RC': 'numeric', 'NM_001609': 'numeric', 'Contig17206_RC': 'numeric', 'NM_001611': 'numeric', 'NM_002341': 'numeric', 'NM_001612': 'numeric', 'NM_002343': 'numeric', 'NM_001615': 'numeric', 'NM_002345': 'numeric', 'NM_003081': 'numeric', 'NM_001627': 'numeric', 'NM_002358': 'numeric', 'Contig50838_RC': 'numeric', 'NM_000900': 'numeric', 'NM_000903': 'numeric', 'NM_001635': 'numeric', 'NM_000909': 'numeric', 'NM_000912': 'numeric', 'NM_001645': 'numeric', 'NM_001647': 'numeric', 'Contig35896_RC': 'numeric', 'NM_000926': 'numeric', 'NM_001657': 'numeric', 'NM_000930': 'numeric', 'NM_000931': 'numeric', 'NM_000936': 'numeric', 'NM_002395': 'numeric', 'NM_001674': 'numeric', 'NM_001676': 'numeric', 'NM_001677': 'numeric', 'X04706': 'numeric', 'D25328': 'numeric', 'Contig37076': 'numeric', 'Contig44366': 'numeric', 'NM_000959': 'numeric', 'Contig46463_RC': 'numeric', 'Contig5443_RC': 'numeric', 'NM_001692': 'numeric', 'NM_000963': 'numeric', 'NM_000964': 'numeric', 'Contig50122_RC': 'numeric', 'Contig25711_RC': 'numeric', 'Contig33121_RC': 'numeric', 'Contig12593_RC': 'numeric', 'U22027': 'numeric', 'U22028': 'numeric', 'U22029': 'numeric', 'AF041410': 'numeric', 'Contig15750_RC': 'numeric', 'Contig26182_RC': 'numeric', 'Contig22423_RC': 'numeric', 'Contig15133_RC': 'numeric', 'X99142': 'numeric', 'U46752': 'numeric', 'X72308': 'numeric', 'Contig25195_RC': 'numeric', 'Contig47045_RC': 'numeric', 'Contig42789_RC': 'numeric', 'Contig27623_RC': 'numeric', 'Contig27014_RC': 'numeric', 'NM_003104': 'numeric', 'Contig56386_RC': 'numeric', 'Contig46909_RC': 'numeric', 'NM_003108': 'numeric', 'Contig41360_RC': 'numeric', 'Contig39385_RC': 'numeric', 'NM_003118': 'numeric', 'Contig52018_RC': 'numeric', 'Contig43645_RC': 'numeric', 'NM_002407': 'numeric', 'Contig20600_RC': 'numeric', 'NM_002411': 'numeric', 'Contig52994_RC': 'numeric', 'NM_002416': 'numeric', 'Contig9541_RC': 'numeric', 'Contig21930_RC': 'numeric', 'Contig50927_RC': 'numeric', 'NM_002421': 'numeric', 'NM_002422': 'numeric', 'NM_002425': 'numeric', 'NM_002426': 'numeric', 'NM_003155': 'numeric', 'NM_002427': 'numeric', 'Contig46802_RC': 'numeric', 'NM_001710': 'numeric', 'NM_002443': 'numeric', 'NM_001717': 'numeric', 'NM_002449': 'numeric', 'NM_001723': 'numeric', 'NM_003181': 'numeric', 'NM_001725': 'numeric', 'NM_002456': 'numeric', 'NM_002457': 'numeric', 'NM_001732': 'numeric', 'NM_002462': 'numeric', 'NM_001734': 'numeric', 'NM_001740': 'numeric', 'NM_002478': 'numeric', 'NM_002483': 'numeric', 'NM_001756': 'numeric', 'NM_001758': 'numeric', 'Contig30045_RC': 'numeric', 'NM_001764': 'numeric', 'Contig21063_RC': 'numeric', 'Contig18502_RC': 'numeric', 'Contig33811_RC': 'numeric', 'Contig37562_RC': 'numeric', 'Contig36440': 'numeric', 'NM_001786': 'numeric', 'Contig15329_RC': 'numeric', 'Contig38517_RC': 'numeric', 'NM_001793': 'numeric', 'Contig7809_RC': 'numeric', 'NM_001797': 'numeric', 'AF090920': 'numeric', 'Contig54547_RC': 'numeric', 'Contig14967_RC': 'numeric', 'Contig61829_RC': 'numeric', 'Contig35765': 'numeric', 'Contig35237_RC': 'numeric', 'AW025980_RC': 'numeric', 'AL133038': 'numeric', 'Contig34258_RC': 'numeric', 'Contig41548_RC': 'numeric', 'AF201951': 'numeric', 'AB041269': 'numeric', 'AL133074': 'numeric', 'Contig50288_RC': 'numeric', 'AL133086': 'numeric', 'AL133087': 'numeric', 'Contig8165_RC': 'numeric', 'Contig33888_RC': 'numeric', 'Contig53445_RC': 'numeric', 'Contig40712_RC': 'numeric', 'Contig23711_RC': 'numeric', 'Contig29755_RC': 'numeric', 'NM_003206': 'numeric', 'NM_003225': 'numeric', 'NM_003226': 'numeric', 'NM_003234': 'numeric', 'NM_003236': 'numeric', 'NM_002509': 'numeric', 'NM_003239': 'numeric', 'NM_002515': 'numeric', 'NM_003246': 'numeric', 'NM_003247': 'numeric', 'NM_003248': 'numeric', 'Contig44439_RC': 'numeric', 'NM_002521': 'numeric', 'NM_003256': 'numeric', 'NM_003258': 'numeric', 'Contig43476_RC': 'numeric', 'NM_001809': 'numeric', 'NM_001814': 'numeric', 'NM_002544': 'numeric', 'NM_002546': 'numeric', 'NM_001819': 'numeric', 'NM_001823': 'numeric', 'NM_003283': 'numeric', 'NM_003287': 'numeric', 'Contig22716_RC': 'numeric', 'NM_001831': 'numeric', 'NM_003294': 'numeric', 'NM_001838': 'numeric', 'Contig52960_RC': 'numeric', 'Contig45670_RC': 'numeric', 'Contig16756_RC': 'numeric', 'NM_002570': 'numeric', 'NM_001844': 'numeric', 'NM_002575': 'numeric', 'L11645': 'numeric', 'Contig15418_RC': 'numeric', 'NM_001853': 'numeric', 'NM_001854': 'numeric', 'NM_002590': 'numeric', 'NM_002591': 'numeric', 'Contig21136_RC': 'numeric', 'Contig29015_RC': 'numeric', 'Contig40196_RC': 'numeric', 'NM_001870': 'numeric', 'NM_001871': 'numeric', 'NM_001872': 'numeric', 'NM_001873': 'numeric', 'NM_001877': 'numeric', 'NM_001878': 'numeric', 'NM_001882': 'numeric', 'Contig28528': 'numeric', 'NM_001884': 'numeric', 'NM_001885': 'numeric', 'NM_001888': 'numeric', 'Contig51981_RC': 'numeric', 'Contig42624_RC': 'numeric', 'Contig40789_RC': 'numeric', 'Contig28549': 'numeric', 'AA600139_RC': 'numeric', 'Contig44909_RC': 'numeric', 'Contig49532_RC': 'numeric', 'Contig39678_RC': 'numeric', 'Contig28028_RC': 'numeric', 'Contig21021_RC': 'numeric', 'Contig31333_RC': 'numeric', 'Contig47832_RC': 'numeric', 'U47671': 'numeric', 'Contig33376_RC': 'numeric', 'Contig30955_RC': 'numeric', 'Contig14683_RC': 'numeric', 'Contig41530_RC': 'numeric', 'Contig38826_RC': 'numeric', 'NM_020038': 'numeric', 'Contig44544_RC': 'numeric', 'NM_004003': 'numeric', 'Contig8839_RC': 'numeric', 'NM_004010': 'numeric', 'U05589': 'numeric', 'Contig29828_RC': 'numeric', 'Contig15531_RC': 'numeric', 'NM_003311': 'numeric', 'NM_012067': 'numeric', 'Contig5710_RC': 'numeric', 'Contig53411_RC': 'numeric', 'NM_002614': 'numeric', 'NM_002620': 'numeric', 'Contig54058': 'numeric', 'NM_002628': 'numeric', 'NM_003358': 'numeric', 'NM_003359': 'numeric', 'NM_004088': 'numeric', 'AB007936': 'numeric', 'Contig25593_RC': 'numeric', 'NM_001901': 'numeric', 'NM_002639': 'numeric', 'NM_003376': 'numeric', 'NM_003378': 'numeric', 'AB007954': 'numeric', 'NM_001920': 'numeric', 'NM_002652': 'numeric', 'NM_001926': 'numeric', 'NM_001928': 'numeric', 'Contig21225_RC': 'numeric', 'R70506_RC': 'numeric', 'NM_003392': 'numeric', 'NM_002666': 'numeric', 'Contig57138_RC': 'numeric', 'NM_001942': 'numeric', 'NM_001944': 'numeric', 'Contig36761_RC': 'numeric', 'Contig48156_RC': 'numeric', 'Contig16595_RC': 'numeric', 'NM_001956': 'numeric', 'NM_002686': 'numeric', 'NM_001958': 'numeric', 'Contig31295_RC': 'numeric', 'NM_001964': 'numeric', 'NM_002697': 'numeric', 'Contig56167_RC': 'numeric', 'NM_001979': 'numeric', 'Contig52182_RC': 'numeric', 'NM_001990': 'numeric', 'NM_001993': 'numeric', 'NM_001999': 'numeric', 'Contig35977': 'numeric', 'Contig35978': 'numeric', 'Contig9681_RC': 'numeric', 'Contig53022_RC': 'numeric', 'Contig46942_RC': 'numeric', 'Contig26310_RC': 'numeric', 'Contig46934_RC': 'numeric', 'Contig22408_RC': 'numeric', 'Contig28970_RC': 'numeric', 'NM_012101': 'numeric', 'Contig46918_RC': 'numeric', 'NM_020130': 'numeric', 'NM_004100': 'numeric', 'X66087': 'numeric', 'NM_004114': 'numeric', 'Contig53357_RC': 'numeric', 'NM_020162': 'numeric', 'NM_020163': 'numeric', 'Contig21187_RC': 'numeric', 'NM_004131': 'numeric', 'NM_020178': 'numeric', 'NM_003412': 'numeric', 'NM_004143': 'numeric', 'NM_003430': 'numeric', 'NM_002705': 'numeric', 'NM_002711': 'numeric', 'NM_004170': 'numeric', 'NM_004171': 'numeric', 'Contig27967_RC': 'numeric', 'NM_004176': 'numeric', 'NM_004181': 'numeric', 'NM_004185': 'numeric', 'NM_004190': 'numeric', 'NM_003462': 'numeric', 'NM_002737': 'numeric', 'NM_003474': 'numeric', 'Contig44260_RC': 'numeric', 'Contig46553_RC': 'numeric', 'NM_003489': 'numeric', 'Contig37571_RC': 'numeric', 'NM_002763': 'numeric', 'NM_002774': 'numeric', 'NM_002775': 'numeric', 'Contig53226_RC': 'numeric', 'Contig21665_RC': 'numeric', 'Contig16202_RC': 'numeric', 'S70004': 'numeric', 'Contig20686_RC': 'numeric', 'Contig8898_RC': 'numeric', 'U64564': 'numeric', 'S62027': 'numeric', 'Contig31862_RC': 'numeric', 'Contig34884_RC': 'numeric', 'Contig2237_RC': 'numeric', 'Contig1508_RC': 'numeric', 'Contig48715_RC': 'numeric', 'Contig48106_RC': 'numeric', 'Contig37898_RC': 'numeric', 'Contig30516_RC': 'numeric', 'Contig48707_RC': 'numeric', 'Contig27120_RC': 'numeric', 'Contig30274_RC': 'numeric', 'Contig33296_RC': 'numeric', 'AF035288': 'numeric', 'Contig31596_RC': 'numeric', 'NM_020215': 'numeric', 'Contig38746_RC': 'numeric', 'Contig19452_RC': 'numeric', 'Contig13866_RC': 'numeric', 'Contig16422_RC': 'numeric', 'NM_004203': 'numeric', 'NM_020244': 'numeric', 'NM_004207': 'numeric', 'Contig29147_RC': 'numeric', 'NM_004213': 'numeric', 'NM_012242': 'numeric', 'Contig45786_RC': 'numeric', 'AB040886': 'numeric', 'AB018289': 'numeric', 'NM_003500': 'numeric', 'NM_003506': 'numeric', 'NM_003508': 'numeric', 'NM_003512': 'numeric', 'NM_004244': 'numeric', 'NM_003516': 'numeric', 'NM_004245': 'numeric', 'NM_012269': 'numeric', 'NM_003520': 'numeric', 'NM_004252': 'numeric', 'NM_002800': 'numeric', 'Contig53506': 'numeric', 'NM_004265': 'numeric', 'NM_002809': 'numeric', 'NM_003538': 'numeric', 'NM_002820': 'numeric', 'NM_003561': 'numeric', 'NM_004291': 'numeric', 'NM_002844': 'numeric', 'NM_003578': 'numeric', 'Contig28670_RC': 'numeric', 'NM_002852': 'numeric', 'NM_002854': 'numeric', 'NM_002855': 'numeric', 'Contig53307_RC': 'numeric', 'NM_002864': 'numeric', 'Contig52945_RC': 'numeric', 'NM_002888': 'numeric', 'AF172932': 'numeric', 'NM_002899': 'numeric', 'Contig36064_RC': 'numeric', 'Contig15169_RC': 'numeric', 'Contig38500_RC': 'numeric', 'Contig34372_RC': 'numeric', 'Contig44870': 'numeric', 'Contig50628_RC': 'numeric', 'Contig50019_RC': 'numeric', 'Contig6212_RC': 'numeric', 'Contig45397_RC': 'numeric', 'AF052090': 'numeric', 'AF052095': 'numeric', 'Contig34957_RC': 'numeric', 'Contig43096_RC': 'numeric', 'Contig45389_RC': 'numeric', 'Contig50979_RC': 'numeric', 'Contig15038_RC': 'numeric', 'NM_021012': 'numeric', 'NM_021015': 'numeric', 'AB040900': 'numeric', 'AB018305': 'numeric', 'AL117406': 'numeric', 'Contig39556_RC': 'numeric', 'AB018311': 'numeric', 'AL117418': 'numeric', 'AB040923': 'numeric', 'AB040926': 'numeric', 'AB040930': 'numeric', 'NM_005010': 'numeric', 'AB018345': 'numeric', 'NM_005025': 'numeric', 'NM_012319': 'numeric', 'NM_021069': 'numeric', 'Contig40552_RC': 'numeric', 'AB040957': 'numeric', 'AL117452': 'numeric', 'NM_021076': 'numeric', 'X56807': 'numeric', 'Contig28866_RC': 'numeric', 'NM_004315': 'numeric', 'NM_005046': 'numeric', 'NM_012337': 'numeric', 'NM_012339': 'numeric', 'AB032953': 'numeric', 'NM_012342': 'numeric', 'AB032962': 'numeric', 'Contig30833_RC': 'numeric', 'M27749': 'numeric', 'Contig42228_RC': 'numeric', 'Contig27294_RC': 'numeric', 'NM_020372': 'numeric', 'NM_005063': 'numeric', 'NM_020373': 'numeric', 'NM_004335': 'numeric', 'NM_004336': 'numeric', 'NM_005067': 'numeric', 'NM_005069': 'numeric', 'Contig56434_RC': 'numeric', 'Contig44287_RC': 'numeric', 'NM_003613': 'numeric', 'NM_003615': 'numeric', 'NM_004345': 'numeric', 'NM_003617': 'numeric', 'NM_004351': 'numeric', 'NM_005080': 'numeric', 'NM_004354': 'numeric', 'NM_005084': 'numeric', 'NM_004358': 'numeric', 'NM_004360': 'numeric', 'NM_004361': 'numeric', 'NM_004362': 'numeric', 'NM_004369': 'numeric', 'Contig31546_RC': 'numeric', 'NM_003641': 'numeric', 'NM_003645': 'numeric', 'NM_004374': 'numeric', 'NM_004378': 'numeric', 'NM_012397': 'numeric', 'Contig18296_RC': 'numeric', 'Contig45600': 'numeric', 'NM_002923': 'numeric', 'NM_003652': 'numeric', 'NM_004385': 'numeric', 'NM_003657': 'numeric', 'NM_002932': 'numeric', 'NM_004392': 'numeric', 'Contig47077': 'numeric', 'AJ270996': 'numeric', 'Contig27405_RC': 'numeric', 'NM_002963': 'numeric', 'NM_002964': 'numeric', 'NM_002965': 'numeric', 'Contig23420_RC': 'numeric', 'U80736': 'numeric', 'Contig37483_RC': 'numeric', 'Contig43435_RC': 'numeric', 'Contig38438_RC': 'numeric', 'NM_002983': 'numeric', 'NM_002984': 'numeric', 'NM_002985': 'numeric', 'NM_002986': 'numeric', 'NM_002988': 'numeric', 'NM_002989': 'numeric', 'NM_002996': 'numeric', 'NM_002997': 'numeric', 'U56725': 'numeric', 'Contig54603_RC': 'numeric', 'AF052176': 'numeric', 'Contig32136_RC': 'numeric', 'Contig29699': 'numeric', 'Contig6051_RC': 'numeric', 'Contig11142_RC': 'numeric', 'Contig9229': 'numeric', 'Contig50360_RC': 'numeric', 'Contig27032_RC': 'numeric', 'Contig53007_RC': 'numeric', 'Contig57359_RC': 'numeric', 'NM_021127': 'numeric', 'NM_021136': 'numeric', 'NM_021139': 'numeric', 'NM_005101': 'numeric', 'NM_020411': 'numeric', 'AL133566': 'numeric', 'NM_021147': 'numeric', 'Contig442_RC': 'numeric', 'Contig25090_RC': 'numeric', 'Contig52629_RC': 'numeric', 'Contig28947_RC': 'numeric', 'Contig1063_RC': 'numeric', 'AL117553': 'numeric', 'NM_005130': 'numeric', 'NM_005132': 'numeric', 'NM_004405': 'numeric', 'NM_004406': 'numeric', 'NM_005139': 'numeric', 'NM_012429': 'numeric', 'NM_004415': 'numeric', 'NM_004417': 'numeric', 'Contig43639_RC': 'numeric', 'NM_012445': 'numeric', 'NM_004430': 'numeric', 'NM_005165': 'numeric', 'NM_020477': 'numeric', 'Contig28697_RC': 'numeric', 'NM_003714': 'numeric', 'NM_012467': 'numeric', 'NM_004448': 'numeric', 'Contig54425': 'numeric', 'NM_005181': 'numeric', 'NM_003725': 'numeric', 'NM_004456': 'numeric', 'NM_005187': 'numeric', 'NM_004460': 'numeric', 'Contig43998_RC': 'numeric', 'NM_005196': 'numeric', 'Contig20953_RC': 'numeric', 'Contig59287_RC': 'numeric', 'NM_003740': 'numeric', 'NM_004472': 'numeric', 'Contig50822_RC': 'numeric', 'NM_004482': 'numeric', 'NM_004484': 'numeric', 'NM_004490': 'numeric', 'NM_004496': 'numeric', 'Contig50814_RC': 'numeric', 'NM_003785': 'numeric', 'NM_003786': 'numeric', 'NM_003787': 'numeric', 'NM_003790': 'numeric', 'Contig38285_RC': 'numeric', 'Contig6848_RC': 'numeric', 'Contig5403_RC': 'numeric', 'AF131741': 'numeric', 'Contig9755_RC': 'numeric', 'AF131756': 'numeric', 'Contig40829_RC': 'numeric', 'AF131770': 'numeric', 'Contig39492_RC': 'numeric', 'AF131784': 'numeric', 'AL133619': 'numeric', 'U06715': 'numeric', 'AL133644': 'numeric', 'AL117612': 'numeric', 'NM_013230': 'numeric', 'NM_013231': 'numeric', 'NM_005213': 'numeric', 'AL117638': 'numeric', 'NM_005218': 'numeric', 'NM_013253': 'numeric', 'NM_005235': 'numeric', 'AF176012': 'numeric', 'NM_004522': 'numeric', 'NM_005252': 'numeric', 'NM_004525': 'numeric', 'X16302': 'numeric', 'NM_003806': 'numeric', 'Contig47220': 'numeric', 'Contig52970_RC': 'numeric', 'NM_005288': 'numeric', 'Contig19179_RC': 'numeric', 'NM_003832': 'numeric', 'Contig54536': 'numeric', 'NM_004566': 'numeric', 'NM_003843': 'numeric', 'Contig38983_RC': 'numeric', 'NM_004585': 'numeric', 'NM_003862': 'numeric', 'NM_004594': 'numeric', 'Contig59870_RC': 'numeric', 'NM_003878': 'numeric', 'Contig41905_RC': 'numeric', 'NM_003881': 'numeric', 'Contig46567': 'numeric', 'NM_003888': 'numeric', 'NM_003890': 'numeric', 'NM_003897': 'numeric', 'Contig15313_RC': 'numeric', 'Contig19064_RC': 'numeric', 'Contig28038_RC': 'numeric', 'Contig51967_RC': 'numeric', 'Contig37873': 'numeric', 'AF131851': 'numeric', 'Contig35814_RC': 'numeric', 'Contig45291_RC': 'numeric', 'Contig43833_RC': 'numeric', 'Contig55228_RC': 'numeric', 'Contig1850_RC': 'numeric', 'NM_014004': 'numeric', 'Contig20629_RC': 'numeric', 'NM_006006': 'numeric', 'AF026941': 'numeric', 'NM_006017': 'numeric', 'Contig14812_RC': 'numeric', 'NM_006025': 'numeric', 'AL109706': 'numeric', 'NM_013324': 'numeric', 'Contig46597_RC': 'numeric', 'Contig16262_RC': 'numeric', 'NM_005310': 'numeric', 'X57809': 'numeric', 'NM_005319': 'numeric', 'NM_005320': 'numeric', 'X57819': 'numeric', 'NM_005325': 'numeric', 'NM_014073': 'numeric', 'NM_014074': 'numeric', 'NM_005326': 'numeric', 'NM_020639': 'numeric', 'NM_014086': 'numeric', 'NM_013357': 'numeric', 'NM_005342': 'numeric', 'NM_006071': 'numeric', 'NM_006073': 'numeric', 'NM_013363': 'numeric', 'NM_004616': 'numeric', 'NM_020659': 'numeric', 'U83115': 'numeric', 'NM_013372': 'numeric', 'NM_006086': 'numeric', 'NM_005357': 'numeric', 'NM_005362': 'numeric', 'NM_020672': 'numeric', 'NM_006096': 'numeric', 'NM_005368': 'numeric', 'Contig35298_RC': 'numeric', 'NM_005375': 'numeric', 'AJ249377': 'numeric', 'NM_005382': 'numeric', 'Contig7755_RC': 'numeric', 'AL109791': 'numeric', 'NM_004664': 'numeric', 'NM_003937': 'numeric', 'NM_005396': 'numeric', 'NM_005398': 'numeric', 'NM_004670': 'numeric', 'NM_004684': 'numeric', 'Contig51463_RC': 'numeric', 'NM_004694': 'numeric', 'NM_004695': 'numeric', 'NM_004696': 'numeric', 'NM_003975': 'numeric', 'NM_003979': 'numeric', 'Contig54477_RC': 'numeric', 'NM_003981': 'numeric', 'NM_003986': 'numeric', 'Contig27900_RC': 'numeric', 'Contig48043_RC': 'numeric', 'Contig39670_RC': 'numeric', 'Contig53641_RC': 'numeric', 'Contig27749_RC': 'numeric', 'Contig50603_RC': 'numeric', 'Contig54354_RC': 'numeric', 'Contig9810_RC': 'numeric', 'Contig37946_RC': 'numeric', 'Contig3607_RC': 'numeric', 'NM_014112': 'numeric', 'NM_006103': 'numeric', 'NM_006107': 'numeric', 'NM_006113': 'numeric', 'Contig8222_RC': 'numeric', 'NM_006115': 'numeric', 'Contig53968_RC': 'numeric', 'NM_013409': 'numeric', 'Contig51066_RC': 'numeric', 'NM_013410': 'numeric', 'NM_006121': 'numeric', 'M29540': 'numeric', 'Contig35629_RC': 'numeric', 'NM_013421': 'numeric', 'NM_005408': 'numeric', 'NM_005409': 'numeric', 'NM_006138': 'numeric', 'Contig20603_RC': 'numeric', 'NM_005410': 'numeric', 'X82693': 'numeric', 'NM_006142': 'numeric', 'Contig46204_RC': 'numeric', 'NM_006157': 'numeric', 'NM_006159': 'numeric', 'NM_004701': 'numeric', 'NM_004702': 'numeric', 'Contig11613_RC': 'numeric', 'NM_004711': 'numeric', 'NM_004734': 'numeric', 'NM_006198': 'numeric', 'AF000990': 'numeric', 'Contig40368_RC': 'numeric', 'NM_005478': 'numeric', 'NM_004750': 'numeric', 'AJ223352': 'numeric', 'AJ223353': 'numeric', 'NM_004774': 'numeric', 'Contig23502_RC': 'numeric', 'NM_004780': 'numeric', 'Contig66705_RC': 'numeric', 'NM_004792': 'numeric', 'NM_004796': 'numeric', 'X07834': 'numeric', 'Contig56143_RC': 'numeric', 'Contig11097_RC': 'numeric', 'Contig45703_RC': 'numeric', 'Contig31864_RC': 'numeric', 'J02639': 'numeric', 'Contig38171_RC': 'numeric', 'AF116715': 'numeric', 'Contig17411_RC': 'numeric', 'Contig33899_RC': 'numeric', 'Contig44708_RC': 'numeric', 'Contig43136_RC': 'numeric', 'Contig46301_RC': 'numeric', 'NM_014211': 'numeric', 'NM_014214': 'numeric', 'Contig42774_RC': 'numeric', 'NM_006206': 'numeric', 'NM_006207': 'numeric', 'Contig38040_RC': 'numeric', 'Contig54913_RC': 'numeric', 'NM_014241': 'numeric', 'NM_006226': 'numeric', 'NM_014246': 'numeric', 'NM_006235': 'numeric', 'NM_014258': 'numeric', 'NM_006240': 'numeric', 'NM_005514': 'numeric', 'NM_005518': 'numeric', 'Contig47381_RC': 'numeric', 'NM_014274': 'numeric', 'Contig50769_RC': 'numeric', 'Contig47982_RC': 'numeric', 'NM_005532': 'numeric', 'NM_004807': 'numeric', 'NM_014286': 'numeric', 'NM_005544': 'numeric', 'NM_006274': 'numeric', 'Contig57076_RC': 'numeric', 'Contig48328_RC': 'numeric', 'NM_005558': 'numeric', 'NM_004833': 'numeric', 'NM_005564': 'numeric', 'NM_004835': 'numeric', 'Contig16759_RC': 'numeric', 'NM_005573': 'numeric', 'Contig20793_RC': 'numeric', 'NM_005586': 'numeric', 'Contig14458_RC': 'numeric', 'NM_004864': 'numeric', 'NM_004867': 'numeric', 'Contig3682_RC': 'numeric', 'NM_004878': 'numeric', 'Contig52947_RC': 'numeric', 'NM_004887': 'numeric', 'Contig48806_RC': 'numeric', 'Contig29369_RC': 'numeric', 'AL353944': 'numeric', 'J04162': 'numeric', 'Contig56583_RC': 'numeric', 'Contig37890_RC': 'numeric', 'AB029018': 'numeric', 'Contig55838_RC': 'numeric', 'Contig39100_RC': 'numeric', 'Contig54867_RC': 'numeric', 'Contig11648_RC': 'numeric', 'NM_007019': 'numeric', 'Contig51595_RC': 'numeric', 'NM_014321': 'numeric', 'NM_007036': 'numeric', 'NM_007038': 'numeric', 'Contig56307': 'numeric', 'NM_006334': 'numeric', 'NM_006338': 'numeric', 'NM_007069': 'numeric', 'NM_006344': 'numeric', 'NM_014365': 'numeric', 'NM_014373': 'numeric', 'NM_007088': 'numeric', 'Contig37743_RC': 'numeric', 'NM_006379': 'numeric', 'NM_014398': 'numeric', 'NM_014399': 'numeric', 'Contig28152_RC': 'numeric', 'NM_004920': 'numeric', 'NM_004923': 'numeric', 'AK000004': 'numeric', 'Contig33750_RC': 'numeric', 'NM_020974': 'numeric', 'NM_006398': 'numeric', 'Contig40889_RC': 'numeric', 'NM_005672': 'numeric', 'NM_004950': 'numeric', 'Contig49093': 'numeric', 'NM_020990': 'numeric', 'NM_020994': 'numeric', 'NM_005688': 'numeric', 'Contig30569_RC': 'numeric', 'NM_004963': 'numeric', 'Contig11275_RC': 'numeric', 'U66702': 'numeric', 'AF079529': 'numeric', 'AK000060': 'numeric', 'NM_004986': 'numeric', 'NM_004988': 'numeric', 'Contig33726_RC': 'numeric', 'NM_004994': 'numeric', 'Contig50719_RC': 'numeric', 'Contig43195_RC': 'numeric', 'X93006': 'numeric', 'AL080059': 'numeric', 'AL080079': 'numeric', 'Contig60315_RC': 'numeric', 'Contig44652_RC': 'numeric', 'AL080094': 'numeric', 'Contig38918_RC': 'numeric', 'Contig46937_RC': 'numeric', 'Contig1789_RC': 'numeric', 'AL110126': 'numeric', 'Contig57270_RC': 'numeric', 'AL110152': 'numeric', 'NM_007105': 'numeric', 'Contig1682_RC': 'numeric', 'AL110168': 'numeric', 'NM_014405': 'numeric', 'NM_007117': 'numeric', 'Contig40026_RC': 'numeric', 'AL110171': 'numeric', 'AL110181': 'numeric', 'NM_006408': 'numeric', 'AB002351': 'numeric', 'NM_006419': 'numeric', 'Contig51202_RC': 'numeric', 'NM_014443': 'numeric', 'X66945': 'numeric', 'NM_007168': 'numeric', 'AF097021': 'numeric', 'NM_007173': 'numeric', 'NM_005727': 'numeric', 'NM_014479': 'numeric', 'M29873': 'numeric', 'M29874': 'numeric', 'NM_006461': 'numeric', 'NM_005733': 'numeric', 'NM_007191': 'numeric', 'Contig41850_RC': 'numeric', 'Contig52891_RC': 'numeric', 'NM_006475': 'numeric', 'NM_005749': 'numeric', 'AK000106': 'numeric', 'NM_005764': 'numeric', 'AJ225092': 'numeric', 'AJ225093': 'numeric', 'NM_005794': 'numeric', 'Contig56160_RC': 'numeric', 'AK000168': 'numeric', 'Contig51896_RC': 'numeric', 'Contig55181_RC': 'numeric', 'AL080137': 'numeric', 'Contig40238_RC': 'numeric', 'Contig32594_RC': 'numeric', 'NC_001807': 'numeric', 'Contig67169_RC': 'numeric', 'AF101051': 'numeric', 'Contig30519_RC': 'numeric', 'AF222694': 'numeric', 'AL080199': 'numeric', 'Contig6118_RC': 'numeric', 'AL110202': 'numeric', 'Contig41453_RC': 'numeric', 'AB011146': 'numeric', 'Contig31133_RC': 'numeric', 'AL110252': 'numeric', 'Contig6612_RC': 'numeric', 'Contig51749_RC': 'numeric', 'AI497657_RC': 'numeric', 'NM_007231': 'numeric', 'Contig21406_RC': 'numeric', 'Contig28179_RC': 'numeric', 'Contig42759_RC': 'numeric', 'NM_007253': 'numeric', 'NM_006528': 'numeric', 'NM_006529': 'numeric', 'Contig18611_RC': 'numeric', 'NM_006533': 'numeric', 'NM_014553': 'numeric', 'NM_006536': 'numeric', 'Contig50913_RC': 'numeric', 'Contig31476_RC': 'numeric', 'Contig49058_RC': 'numeric', 'NM_006551': 'numeric', 'NM_007281': 'numeric', 'NM_005824': 'numeric', 'Contig31010_RC': 'numeric', 'NM_005832': 'numeric', 'NM_014585': 'numeric', 'Contig32798_RC': 'numeric', 'NM_005842': 'numeric', 'D86974': 'numeric', 'NM_005855': 'numeric', 'Contig57293': 'numeric', 'Contig753_RC': 'numeric', 'AF055033': 'numeric', 'J05125': 'numeric', 'Contig10601_RC': 'numeric', 'Contig30390_RC': 'numeric', 'AL080222': 'numeric', 'AF055084': 'numeric', 'AL080235': 'numeric', 'J05175': 'numeric', 'Contig32667_RC': 'numeric', 'M63438': 'numeric', 'Contig23211_RC': 'numeric', 'Contig24541_RC': 'numeric', 'NM_016002': 'numeric', 'Contig53296_RC': 'numeric', 'NM_015310': 'numeric', 'NM_007315': 'numeric', 'NM_007333': 'numeric', 'NM_006623': 'numeric', 'NM_014668': 'numeric', 'Contig44191_RC': 'numeric', 'Contig54729_RC': 'numeric', 'Contig47439_RC': 'numeric', 'NM_014681': 'numeric', 'NM_005940': 'numeric', 'NM_005941': 'numeric', 'NM_014696': 'numeric', 'NM_005950': 'numeric', 'NM_006681': 'numeric', 'Contig57389': 'numeric', 'NM_013982': 'numeric', 'Contig64688': 'numeric', 'NM_013989': 'numeric', 'NM_005971': 'numeric', 'Contig33126_RC': 'numeric', 'NM_005978': 'numeric', 'AF144054': 'numeric', 'NM_013999': 'numeric', 'NM_005980': 'numeric', 'NM_005982': 'numeric', 'Contig57644_RC': 'numeric', 'AK000345': 'numeric', 'AF224266': 'numeric', 'Contig28030_RC': 'numeric', 'AF053712': 'numeric', 'Contig36499_RC': 'numeric', 'Contig40158_RC': 'numeric', 'U67784': 'numeric', 'AL137274': 'numeric', 'NM_016109': 'numeric', 'Contig51685_RC': 'numeric', 'Contig42328_RC': 'numeric', 'Contig44530_RC': 'numeric', 'NM_016140': 'numeric', 'NM_015417': 'numeric', 'Y16132': 'numeric', 'Contig29822_RC': 'numeric', 'Contig31646_RC': 'numeric', 'NM_014723': 'numeric', 'NM_006705': 'numeric', 'NM_006727': 'numeric', 'Contig20355_RC': 'numeric', 'Contig48400_RC': 'numeric', 'Y14737': 'numeric', 'NM_006744': 'numeric', 'NM_014767': 'numeric', 'Contig14996_RC': 'numeric', 'NM_006751': 'numeric', 'AK001101': 'numeric', 'NM_014781': 'numeric', 'NM_006765': 'numeric', 'NM_006769': 'numeric', 'NM_014790': 'numeric', 'T50661_RC': 'numeric', 'NM_006787': 'numeric', 'Contig35875_RC': 'numeric', 'Contig57725_RC': 'numeric', 'Contig37702_RC': 'numeric', 'AF070536': 'numeric', 'Contig47405_RC': 'numeric', 'K02276': 'numeric', 'AK000451': 'numeric', 'Contig399_RC': 'numeric', 'Contig52737_RC': 'numeric', 'AL137334': 'numeric', 'AL137342': 'numeric', 'AL137343': 'numeric', 'Contig3464_RC': 'numeric', 'X52015': 'numeric', 'Contig38901_RC': 'numeric', 'Contig31142_RC': 'numeric', 'M54927': 'numeric', 'Contig44010_RC': 'numeric', 'Contig48971_RC': 'numeric', 'NM_016220': 'numeric', 'NM_015507': 'numeric', 'NM_015515': 'numeric', 'NM_016249': 'numeric', 'NM_016260': 'numeric', 'NM_016267': 'numeric', 'Contig23466_RC': 'numeric', 'Contig53944_RC': 'numeric', 'NM_006804': 'numeric', 'NM_006820': 'numeric', 'NM_006823': 'numeric', 'NM_006829': 'numeric', 'NM_006845': 'numeric', 'NM_006847': 'numeric', 'Contig43983_RC': 'numeric', 'NM_014875': 'numeric', 'Contig52957_RC': 'numeric', 'NM_006868': 'numeric', 'Contig38520_RC': 'numeric', 'Contig51994_RC': 'numeric', 'NM_014897': 'numeric', 'NM_014899': 'numeric', 'Contig34009_RC': 'numeric', 'AJ224741': 'numeric', 'Contig57595': 'numeric', 'Contig32192': 'numeric', 'Contig30016_RC': 'numeric', 'AF070632': 'numeric', 'Contig51369_RC': 'numeric', 'Contig39834_RC': 'numeric', 'Contig14954_RC': 'numeric', 'Contig10961_RC': 'numeric', 'Contig21619_RC': 'numeric', 'Contig16531_RC': 'numeric', 'AL137449': 'numeric', 'Contig30260_RC': 'numeric', 'AL049257': 'numeric', 'AL049265': 'numeric', 'Contig38589_RC': 'numeric', 'AL049279': 'numeric', 'Contig55725_RC': 'numeric', 'NM_016348': 'numeric', 'NM_016352': 'numeric', 'NM_016358': 'numeric', 'NM_016359': 'numeric', 'NM_014903': 'numeric', 'NM_016364': 'numeric', 'Contig47456_RC': 'numeric', 'Contig21847_RC': 'numeric', 'AB028974': 'numeric', 'Contig57903_RC': 'numeric', 'Z11887': 'numeric', 'AK002005': 'numeric', 'Contig57631': 'numeric', 'AK002016': 'numeric', 'Contig48913_RC': 'numeric', 'K02403': 'numeric', 'Contig57653_RC': 'numeric', 'Contig30480_RC': 'numeric', 'X01394': 'numeric', 'AK002088': 'numeric', 'Contig34449_RC': 'numeric', 'Contig46362_RC': 'numeric', 'AK000660': 'numeric', 'Contig54365_RC': 'numeric', 'Contig56801_RC': 'numeric', 'AL137517': 'numeric', 'AL137540': 'numeric', 'Contig19384_RC': 'numeric', 'Contig41983_RC': 'numeric', 'AL049337': 'numeric', 'Contig36520_RC': 'numeric', 'AB037734': 'numeric', 'AL137566': 'numeric', 'AL137567': 'numeric', 'Contig51220_RC': 'numeric', 'AB037745': 'numeric', 'Contig5804_RC': 'numeric', 'Contig440': 'numeric', 'AB037763': 'numeric', 'NM_015719': 'numeric', 'AB037791': 'numeric', 'NM_016459': 'numeric', 'AF179224': 'numeric', 'NM_016471': 'numeric', 'Contig44265_RC': 'numeric', 'AK002107': 'numeric', 'AF064200': 'numeric', 'AK002138': 'numeric', 'Contig53598_RC': 'numeric', 'AK001423': 'numeric', 'Contig47781_RC': 'numeric', 'Contig46435_RC': 'numeric', 'Contig49342_RC': 'numeric', 'Contig51775_RC': 'numeric', 'AL137619': 'numeric', 'Contig13879_RC': 'numeric', 'AL049423': 'numeric', 'Contig56390_RC': 'numeric', 'AB037821': 'numeric', 'AB037836': 'numeric', 'AL137669': 'numeric', 'Contig23108_RC': 'numeric', 'AB037848': 'numeric', 'Contig51660_RC': 'numeric', 'AF005487': 'numeric', 'AL137698': 'numeric', 'X51630': 'numeric', 'Contig16786_RC': 'numeric', 'NM_016569': 'numeric', 'NM_016577': 'numeric', 'AL359053': 'numeric', 'AL359062': 'numeric', 'Contig24682_RC': 'numeric', 'Contig15325_RC': 'numeric', 'Contig39242_RC': 'numeric', 'Contig2339_RC': 'numeric', 'Contig49855': 'numeric', 'Contig39226_RC': 'numeric', 'Contig30384_RC': 'numeric', 'Contig46508_RC': 'numeric', 'Contig45537_RC': 'numeric', 'Contig51255_RC': 'numeric', 'Contig42882_RC': 'numeric', 'Contig3313': 'numeric', 'Contig49790_RC': 'numeric', 'NM_018004': 'numeric', 'AL137725': 'numeric', 'NM_018014': 'numeric', 'Contig47106_RC': 'numeric', 'NM_018043': 'numeric', 'AL137761': 'numeric', 'Contig41887_RC': 'numeric', 'NM_016619': 'numeric', 'Contig42751_RC': 'numeric', 'Contig41413_RC': 'numeric', 'Contig53183_RC': 'numeric', 'NM_016640': 'numeric', 'X52486': 'numeric', 'AJ275978': 'numeric', 'Contig40434_RC': 'numeric', 'X03084': 'numeric', 'Contig30481_RC': 'numeric', 'Contig42011_RC': 'numeric', 'Contig4380_RC': 'numeric', 'Contig20137_RC': 'numeric', 'Contig58260_RC': 'numeric', 'Contig45511_RC': 'numeric', 'Contig50357_RC': 'numeric', 'AF020919': 'numeric', 'Contig46089_RC': 'numeric', 'NM_018104': 'numeric', 'Contig38580_RC': 'numeric', 'NM_018136': 'numeric', 'NM_000028': 'numeric', 'NM_000029': 'numeric', 'NM_017414': 'numeric', 'Contig15384_RC': 'numeric', 'NM_000037': 'numeric', 'NM_017422': 'numeric', 'NM_017423': 'numeric', 'Contig52543_RC': 'numeric', 'NM_000044': 'numeric', 'NM_018166': 'numeric', 'Contig14647_RC': 'numeric', 'NM_000050': 'numeric', 'NM_000067': 'numeric', 'NM_017459': 'numeric', 'AB020689': 'numeric', 'NM_000077': 'numeric', 'Contig64297_RC': 'numeric', 'NM_000089': 'numeric', 'Contig27882_RC': 'numeric', 'NM_000090': 'numeric', 'NM_000095': 'numeric', 'NM_000096': 'numeric', 'Contig49589_RC': 'numeric', 'Contig57142_RC': 'numeric', 'Contig46452_RC': 'numeric', 'U79293': 'numeric', 'U79299': 'numeric', 'Contig41587_RC': 'numeric', 'AF073299': 'numeric', 'AF047826': 'numeric', 'Contig60157_RC': 'numeric', 'AF103375': 'numeric', 'AF007150': 'numeric', 'AF007153': 'numeric', 'NM_018208': 'numeric', 'NM_018215': 'numeric', 'Contig35030_RC': 'numeric', 'NM_000104': 'numeric', 'Contig39616_RC': 'numeric', 'M30818': 'numeric', 'NM_000111': 'numeric', 'NM_000125': 'numeric', 'NM_000129': 'numeric', 'NM_000141': 'numeric', 'Contig47994_RC': 'numeric', 'NM_018265': 'numeric', 'NM_016817': 'numeric', 'NM_000165': 'numeric', 'NM_000168': 'numeric', 'NM_000169': 'numeric', 'Contig54667_RC': 'numeric', 'Contig29647_RC': 'numeric', 'Contig42139': 'numeric', 'NM_000187': 'numeric', 'Contig55997_RC': 'numeric', 'NM_017579': 'numeric', 'NM_000196': 'numeric', 'NM_009585': 'numeric', 'NM_009588': 'numeric', 'Contig1018_RC': 'numeric', 'Contig43368_RC': 'numeric', 'Contig41676_RC': 'numeric', 'Contig42532_RC': 'numeric', 'AF058075': 'numeric', 'Contig43253_RC': 'numeric', 'AF063936': 'numeric', 'Contig42274_RC': 'numeric', 'Contig32563_RC': 'numeric', 'AF103458': 'numeric', 'Z48633': 'numeric', 'Contig23581_RC': 'numeric', 'NM_019000': 'numeric', 'Contig33284_RC': 'numeric', 'NM_019013': 'numeric', 'Contig28888_RC': 'numeric', 'Contig375_RC': 'numeric', 'NM_018306': 'numeric', 'D90070': 'numeric', 'NM_019049': 'numeric', 'NM_019058': 'numeric', 'NM_000222': 'numeric', 'NM_000224': 'numeric', 'NM_000228': 'numeric', 'NM_000230': 'numeric', 'NM_000237': 'numeric', 'NM_000238': 'numeric', 'NM_000239': 'numeric', 'NM_000240': 'numeric', 'Contig51117_RC': 'numeric', 'NM_000266': 'numeric', 'NM_000269': 'numeric', 'Contig42227': 'numeric', 'NM_000295': 'numeric', 'NM_000299': 'numeric', 'NM_017680': 'numeric', 'AF234532': 'numeric', 'Contig65658_RC': 'numeric', 'Contig48800_RC': 'numeric', 'Contig54968_RC': 'numeric', 'Contig37501_RC': 'numeric', 'Contig24609_RC': 'numeric', 'Contig48518_RC': 'numeric', 'NM_018407': 'numeric', 'Contig53281_RC': 'numeric', 'NM_018410': 'numeric', 'NM_018422': 'numeric', 'AL049932': 'numeric', 'NM_000320': 'numeric', 'NM_000323': 'numeric', 'NM_000324': 'numeric', 'NM_000331': 'numeric', 'NM_001062': 'numeric', 'NM_001063': 'numeric', 'NM_001073': 'numeric', 'NM_001074': 'numeric', 'Contig1805_RC': 'numeric', 'NM_000346': 'numeric', 'NM_001076': 'numeric', 'NM_001078': 'numeric', 'AL049963': 'numeric', 'NM_017731': 'numeric', 'NM_000353': 'numeric', 'NM_001085': 'numeric', 'NM_000358': 'numeric', 'NM_001089': 'numeric', 'NM_018476': 'numeric', 'NM_000362': 'numeric', 'NM_000363': 'numeric', 'AL049987': 'numeric', 'Contig24252_RC': 'numeric', 'NM_000370': 'numeric', 'L27560': 'numeric', 'NM_000381': 'numeric', 'NM_000393': 'numeric', 'NM_000396': 'numeric', 'NM_000399': 'numeric', 'NM_017786': 'numeric', 'Contig56765_RC': 'numeric', 'AF113007': 'numeric', 'X02761': 'numeric', 'M90657': 'numeric', 'Contig16453_RC': 'numeric', 'AB023144': 'numeric', 'Contig54325_RC': 'numeric', 'NM_001102': 'numeric', 'NM_001109': 'numeric', 'Contig38654_RC': 'numeric', 'NM_001124': 'numeric', 'NM_001129': 'numeric', 'Contig32602_RC': 'numeric', 'NM_001144': 'numeric', 'NM_018530': 'numeric', 'NM_000421': 'numeric', 'NM_001150': 'numeric', 'NM_000422': 'numeric', 'NM_000424': 'numeric', 'Contig13300_RC': 'numeric', 'Contig43026_RC': 'numeric', 'NM_000439': 'numeric', 'NM_001168': 'numeric', 'NM_017821': 'numeric', 'Contig56503_RC': 'numeric', 'Contig51037_RC': 'numeric', 'NM_001185': 'numeric', 'NM_001189': 'numeric', 'NM_017852': 'numeric', 'Contig57825_RC': 'numeric', 'NM_000477': 'numeric', 'NM_017870': 'numeric', 'Contig32336_RC': 'numeric', 'NM_017878': 'numeric', 'NM_000493': 'numeric', 'AW518944_RC': 'numeric', 'NM_000495': 'numeric', 'Contig34395_RC': 'numeric', 'U96394': 'numeric', 'Contig55883_RC': 'numeric', 'Contig30995_RC': 'numeric', 'Contig41804_RC': 'numeric', 'Contig54295_RC': 'numeric', 'AB023211': 'numeric', 'U28831': 'numeric', 'M33318': 'numeric', 'Contig54414_RC': 'numeric', 'Contig41538_RC': 'numeric', 'Contig1239_RC': 'numeric', 'Contig42402_RC': 'numeric', 'NM_001203': 'numeric', 'AB014533': 'numeric', 'AB014534': 'numeric', 'NM_001216': 'numeric', 'NM_001218': 'numeric', 'NM_000507': 'numeric', 'NM_000509': 'numeric', 'NM_000518': 'numeric', 'Contig43708_RC': 'numeric', 'NM_001254': 'numeric', 'L10333': 'numeric', 'NM_001267': 'numeric', 'NM_018653': 'numeric', 'NM_001275': 'numeric', 'NM_001276': 'numeric', 'Contig2446_RC': 'numeric', 'Contig50529': 'numeric', 'NM_017954': 'numeric', 'NM_017957': 'numeric', 'Contig15190_RC': 'numeric', 'NM_000582': 'numeric', 'NM_000584': 'numeric', 'Contig13724_RC': 'numeric', 'NM_000592': 'numeric', 'NM_000597': 'numeric', 'NM_000599': 'numeric', 'Contig42582': 'numeric', 'Contig21493_RC': 'numeric', 'Contig54993_RC': 'numeric', 'Contig58512_RC': 'numeric', 'Contig4382_RC': 'numeric', 'AL050202': 'numeric', 'AL050227': 'numeric', 'AF111849': 'numeric', 'NM_002001': 'numeric', 'NM_002023': 'numeric', 'NM_001306': 'numeric', 'NM_002036': 'numeric', 'NM_002038': 'numeric', 'NM_002048': 'numeric', 'AB006625': 'numeric', 'NM_002051': 'numeric', 'NM_002053': 'numeric', 'NM_001327': 'numeric', 'NM_000600': 'numeric', 'NM_001333': 'numeric', 'NM_000607': 'numeric', 'NM_001336': 'numeric', 'NM_001338': 'numeric', 'NM_001353': 'numeric', 'NM_000624': 'numeric', 'NM_002089': 'numeric', 'Contig30213_RC': 'numeric', 'Contig33235_RC': 'numeric', 'NM_000633': 'numeric', 'NM_002091': 'numeric', 'NM_001362': 'numeric', 'NM_000636': 'numeric', 'Contig5549_RC': 'numeric', 'NM_000642': 'numeric', 'NM_000646': 'numeric', 'Contig51558_RC': 'numeric', 'NM_001387': 'numeric', 'NM_000662': 'numeric', 'NM_001393': 'numeric', 'NM_001394': 'numeric', 'NM_001395': 'numeric', 'NM_000667': 'numeric', 'NM_000668': 'numeric', 'Contig693_RC': 'numeric', 'NM_000685': 'numeric', 'NM_000693': 'numeric', 'NM_000695': 'numeric', 'Contig14284_RC': 'numeric', 'Contig43791_RC': 'numeric', 'V00522': 'numeric', 'Contig31771_RC': 'numeric', 'Contig40128_RC': 'numeric', 'Contig50950_RC': 'numeric', 'Contig34303_RC': 'numeric', 'NM_002104': 'numeric', 'NM_002121': 'numeric', 'NM_002122': 'numeric', 'NM_002124': 'numeric', 'NM_002125': 'numeric', 'NM_002127': 'numeric', 'NM_002135': 'numeric', 'Contig49079_RC': 'numeric', 'NM_002145': 'numeric', 'NM_002147': 'numeric', 'U10991': 'numeric', 'NM_002160': 'numeric', 'NM_001432': 'numeric', 'NM_002164': 'numeric', 'NM_001438': 'numeric', 'NM_001444': 'numeric', 'NM_001446': 'numeric', 'NM_001448': 'numeric', 'NM_001450': 'numeric', 'NM_001453': 'numeric', 'NM_000727': 'numeric', 'NM_000734': 'numeric', 'NM_000735': 'numeric', 'NM_002193': 'numeric', 'NM_002196': 'numeric', 'M24895': 'numeric', 'NM_019598': 'numeric', 'NM_000764': 'numeric', 'NM_000766': 'numeric', 'NM_000767': 'numeric', 'Contig57584_RC': 'numeric', 'NM_000779': 'numeric', 'NM_000783': 'numeric', 'NM_000799': 'numeric', 'Contig34989_RC': 'numeric', 'Contig41813_RC': 'numeric', 'Contig7558_RC': 'numeric', 'Contig42518_RC': 'numeric', 'AL157488': 'numeric', 'Contig17248_RC': 'numeric', 'AL157492': 'numeric', 'Contig51151_RC': 'numeric', 'Contig58301_RC': 'numeric', 'NM_002201': 'numeric', 'Contig63748_RC': 'numeric', 'NM_002216': 'numeric', 'NM_001504': 'numeric', 'NM_001505': 'numeric', 'NM_001511': 'numeric', 'NM_002245': 'numeric', 'NM_018901': 'numeric', 'NM_002250': 'numeric', 'NM_001523': 'numeric', 'NM_018910': 'numeric', 'NM_000802': 'numeric', 'NM_002266': 'numeric', 'NM_001540': 'numeric', 'NM_002274': 'numeric', 'NM_001546': 'numeric', 'NM_002275': 'numeric', 'NM_002276': 'numeric', 'NM_001548': 'numeric', 'Contig51486_RC': 'numeric', 'NM_000824': 'numeric', 'NM_001554': 'numeric', 'NM_000826': 'numeric', 'NM_001555': 'numeric', 'NM_018942': 'numeric', 'NM_001565': 'numeric', 'NM_002299': 'numeric', 'NM_018950': 'numeric', 'NM_018952': 'numeric', 'Contig55606_RC': 'numeric', 'D25217': 'numeric', 'NM_000846': 'numeric', 'NM_000849': 'numeric', 'Contig29022_RC': 'numeric', 'Contig36312_RC': 'numeric', 'Contig38980_RC': 'numeric', 'NM_000853': 'numeric', 'NM_000854': 'numeric', 'NM_000860': 'numeric', 'Contig29014_RC': 'numeric', 'Contig46616_RC': 'numeric', 'NM_000888': 'numeric', 'NM_000898': 'numeric', 'AF067420': 'numeric'}}}]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "JSON_CONFIG_PATH = '../data/NKI_cleaned/config.json'\n",
    "f = open(JSON_CONFIG_PATH, 'r')\n",
    "global_config = json.load(f)\n",
    "data_path = '../data/NKI_cleaned/NKI_cleaned.csv'\n",
    "global_config['data_config']['path'] = data_path\n",
    "global_config.keys(), global_config.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKiGt4nGLiCu"
   },
   "source": [
    "# ConfigSearcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7vJgR5OOJQ23",
    "outputId": "24649f3b-e375-4ff9-cee7-eed2c6ceda81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys:  dict_keys(['para_name', 'space', 'child_relationship', 'sub_space'])\n",
      "Sub_space:  dict_keys(['binarize_config', 'feature_engineering', 'model_config'])\n"
     ]
    }
   ],
   "source": [
    "from propensity_prediction.config.autotune.param_space import classification_pipeline_space\n",
    "    \n",
    "print ('Keys: ', classification_pipeline_space.keys())\n",
    "print ('Sub_space: ', classification_pipeline_space['sub_space'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "siXKoCrwwP3J",
    "outputId": "24bdb44c-15d2-4edf-9c7b-ecb05b349279"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'para_name': 'classification_pipeline',\n",
       " 'space': ['binarize_config', 'feature_engineering', 'model_config'],\n",
       " 'child_relationship': 'joint',\n",
       " 'sub_space': {'binarize_config': {'suggest': 'choice',\n",
       "   'para_name': 'method',\n",
       "   'space_name': 'binarize.method',\n",
       "   'space': ['threshold', 'gettop'],\n",
       "   'child_relationship': 'conditional',\n",
       "   'sub_space': {'threshold': {'suggest': 'choice',\n",
       "     'para_name': 'threshold_method',\n",
       "     'space_name': 'threshold.method',\n",
       "     'space': ['constant', 'baseline', 'kmeans', 'otsu', 'yen', 'iso']},\n",
       "    'gettop': {}}},\n",
       "  'feature_engineering': {'para_name': 'method',\n",
       "   'space': ['pca', 'scoring'],\n",
       "   'child_relationship': 'joint',\n",
       "   'sub_space': {'pca': {'para_name': 'outputdim',\n",
       "     'space_name': 'pca.outputdim',\n",
       "     'suggest': 'choice',\n",
       "     'space': [None, 5, 10, 20, 100]},\n",
       "    'scoring': {'para_name': 'method',\n",
       "     'child_relationship': 'multi-para',\n",
       "     'space': ['impact', 'scale', 'log'],\n",
       "     'sub_space': {'impact': {'para_name': 'impact',\n",
       "       'space_name': 'scoring.impact',\n",
       "       'suggest': 'choice',\n",
       "       'space': [True, False]},\n",
       "      'scale': {'para_name': 'scale',\n",
       "       'space_name': 'scoring.scale',\n",
       "       'suggest': 'choice',\n",
       "       'space': [True, False]},\n",
       "      'log': {'para_name': 'log',\n",
       "       'space_name': 'scoring.log',\n",
       "       'suggest': 'choice',\n",
       "       'space': [True, False]}}}}},\n",
       "  'model_config': {'para_name': 'model_name',\n",
       "   'child_relationship': 'joint',\n",
       "   'space': ['LogisticRegression', 'Bayesian_LogisticRegression'],\n",
       "   'sub_space': {'LogisticRegression': {'para_name': 'learning_rate',\n",
       "     'space_name': 'LogisticRegression.learning_rate',\n",
       "     'suggest': 'float',\n",
       "     'space': {'low': 0.0005, 'high': 0.01, 'log': False, 'step': 0.0005}},\n",
       "    'Bayesian_LogisticRegression': {'para_name': 'learning_rate',\n",
       "     'space_name': 'Bayesian_LogisticRegression.learning_rate',\n",
       "     'suggest': 'float',\n",
       "     'space': {'low': 0.0005, 'high': 0.01, 'log': False, 'step': 0.0005}}}}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_pipeline_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nAmNQMQHHPAm",
    "outputId": "172d41aa-b815-423e-ad3b-1c27569fc8fc"
   },
   "outputs": [],
   "source": [
    "from propensity_prediction.config.autotune.task_package import Task_Package\n",
    "\n",
    "# Example code\n",
    "\n",
    "from propensity_prediction.config.model_config import ModelConfig\n",
    "from propensity_prediction.config.data_config import ChurnPrediction_DataConfig\n",
    "from propensity_prediction.tasks.churn_prediction.churn_prediction import ChurnPrediction_Task\n",
    "\n",
    "class Tune_ChurnPrediction_ModelConfig(ModelConfig):\n",
    "\tdef __init__(self, pipeline_config):\n",
    "\t\tconfig = {}\n",
    "\t\tconfig['binarize_config'] = pipeline_config['binarize_config']\n",
    "\t\tconfig['feature_engineering'] = pipeline_config['feature_engineering']\n",
    "\t\tconfig.update(self._convert_modelconfig(pipeline_config['model_config']))\n",
    "\t\tsuper().__init__('Ensemble', config)\n",
    "\n",
    "class ChurnPrediction_Package(Task_Package):\n",
    "\tdef __init__(self, global_config):\n",
    "\t\tsuper().__init__(global_config, Tune_ChurnPrediction_ModelConfig, ChurnPrediction_DataConfig, ChurnPrediction_Task)\n",
    "\n",
    "\tdef get_evaluation(self, model_config):  #lower is better\n",
    "\t\teva_res, ens_model = self.exec(model_config)\n",
    "\t\tbin_method = model_config['binarize_config']['method']\n",
    "\t\tres, order = -np.inf, -1 #order == -1 means higher is better\n",
    "\n",
    "\t\tif bin_method == 'gettop':\n",
    "\t\t\tres = eva_res['results']['binarize_methods'][0]['list_results'][1]['results']['f1_score']\n",
    "\t\telif bin_method == 'threshold':\n",
    "\t\t\tthreshold_results = eva_res['results']['binarize_methods'][0]['list_results']\n",
    "\t\t\tfor i in range(len(threshold_results)):\n",
    "\t\t\t\tres_obj = threshold_results[i]\n",
    "\t\t\t\tthres_method, f1_score = res_obj['threshold_method'], res_obj['results']['f1_score']\n",
    "\t\t\t\tif thres_method == model_config['binarize_config']['para']['threshold_method']:\n",
    "\t\t\t\t\tres = f1_score\n",
    "\n",
    "\t\treturn res, order\n",
    "\n",
    "task_package = ChurnPrediction_Package(global_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aidz0LPhQyok",
    "outputId": "76a5e06a-6e80-4519-fccb-14413c192948"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-27 08:35:40,825]\u001b[0m A new study created in memory with name: no-name-34e9a3a6-6bcb-45f1-9feb-8132176391c5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare contextual data\n",
      "Prepare data for models\n",
      "Train ensemble Ensemble\n",
      "+ Prepare model LogisticRegression with label eventdeath\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training with minibacth  0\n",
      "\t+ [iteration 0001] Loss: 0.0150, Best loss: 0.0150\n",
      "\t+ [iteration 0100] Loss: 0.0018, Best loss: 0.0018\n",
      "\t+ [iteration 0100] Loss: 0.0018, Best loss: 0.0018\n",
      "    -> Early stop at epoch 100\n",
      "    Training with minibacth  1\n",
      "\t+ [iteration 0001] Loss: 0.0188, Best loss: 0.0188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/torch/autograd/__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t+ [iteration 0087] Loss: 0.0021, Best loss: 0.0021\n",
      "    -> Early stop at epoch 87\n",
      "    Training with minibacth  2\n",
      "\t+ [iteration 0001] Loss: 0.0128, Best loss: 0.0128\n",
      "\t+ [iteration 0100] Loss: 0.0007, Best loss: 0.0007\n",
      "\t+ [iteration 0105] Loss: 0.0006, Best loss: 0.0006\n",
      "    -> Early stop at epoch 105\n",
      "    Training with minibacth  3\n",
      "\t+ [iteration 0001] Loss: 0.0188, Best loss: 0.0188\n",
      "\t+ [iteration 0100] Loss: 0.0009, Best loss: 0.0009\n",
      "\t+ [iteration 0100] Loss: 0.0009, Best loss: 0.0009\n",
      "    -> Early stop at epoch 100\n",
      "    Training with minibacth  4\n",
      "\t+ [iteration 0001] Loss: 0.0151, Best loss: 0.0151\n",
      "\t+ [iteration 0094] Loss: 0.0007, Best loss: 0.0007\n",
      "    -> Early stop at epoch 94\n",
      "    Training with minibacth  5\n",
      "\t+ [iteration 0001] Loss: 0.0122, Best loss: 0.0122\n",
      "\t+ [iteration 0087] Loss: 0.0000, Best loss: 0.0000\n",
      "    -> Early stop at epoch 87\n",
      "----Running time:  1.091601848602295\n",
      "+ Prepare model Bayesian_LogisticRegression with label eventdeath\n",
      "    Training with minibacth  0\n",
      "\t+ [iteration 0001] Loss: 0.0050, Best loss: 0.0050\n",
      "\t+ [iteration 0051] Loss: 0.0051, Best loss: 0.0050\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  1\n",
      "\t+ [iteration 0001] Loss: 0.0079, Best loss: 0.0079\n",
      "\t+ [iteration 0051] Loss: 0.0079, Best loss: 0.0079\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  2\n",
      "\t+ [iteration 0001] Loss: 0.0079, Best loss: 0.0079\n",
      "\t+ [iteration 0051] Loss: 0.0079, Best loss: 0.0079\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  3\n",
      "\t+ [iteration 0001] Loss: 0.0074, Best loss: 0.0074\n",
      "\t+ [iteration 0051] Loss: 0.0074, Best loss: 0.0074\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  4\n",
      "\t+ [iteration 0001] Loss: 0.0074, Best loss: 0.0074\n",
      "\t+ [iteration 0051] Loss: 0.0074, Best loss: 0.0074\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  5\n",
      "\t+ [iteration 0001] Loss: 0.0000, Best loss: 0.0000\n",
      "\t+ [iteration 0051] Loss: 0.0000, Best loss: 0.0000\n",
      "    -> Early stop at epoch 51\n",
      "----Running time:  0.386641263961792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-27 08:35:53,874]\u001b[0m Trial 0 finished with value: -0.3076923076923077 and parameters: {'binarize.method': 'gettop', 'pca.outputdim': 5, 'scoring.impact': False, 'scoring.scale': False, 'scoring.log': True, 'LogisticRegression.learning_rate': 0.006, 'Bayesian_LogisticRegression.learning_rate': 0.0055}. Best is trial 0 with value: -0.3076923076923077.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare contextual data\n",
      "Prepare data for models\n",
      "Train ensemble Ensemble\n",
      "+ Prepare model LogisticRegression with label eventdeath\n",
      "    Training with minibacth  0\n",
      "\t+ [iteration 0001] Loss: 0.0156, Best loss: 0.0156\n",
      "\t+ [iteration 0100] Loss: 0.0015, Best loss: 0.0015\n",
      "\t+ [iteration 0110] Loss: 0.0014, Best loss: 0.0014\n",
      "    -> Early stop at epoch 110\n",
      "    Training with minibacth  1\n",
      "\t+ [iteration 0001] Loss: 0.0203, Best loss: 0.0203\n",
      "\t+ [iteration 0100] Loss: 0.0015, Best loss: 0.0015\n",
      "\t+ [iteration 0101] Loss: 0.0014, Best loss: 0.0014\n",
      "    -> Early stop at epoch 101\n",
      "    Training with minibacth  2\n",
      "\t+ [iteration 0001] Loss: 0.0132, Best loss: 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t+ [iteration 0100] Loss: 0.0005, Best loss: 0.0005\n",
      "\t+ [iteration 0103] Loss: 0.0005, Best loss: 0.0005\n",
      "    -> Early stop at epoch 103\n",
      "    Training with minibacth  3\n",
      "\t+ [iteration 0001] Loss: 0.0194, Best loss: 0.0194\n",
      "\t+ [iteration 0099] Loss: 0.0007, Best loss: 0.0007\n",
      "    -> Early stop at epoch 99\n",
      "    Training with minibacth  4\n",
      "\t+ [iteration 0001] Loss: 0.0151, Best loss: 0.0151\n",
      "\t+ [iteration 0096] Loss: 0.0005, Best loss: 0.0005\n",
      "    -> Early stop at epoch 96\n",
      "    Training with minibacth  5\n",
      "\t+ [iteration 0001] Loss: 0.0094, Best loss: 0.0094\n",
      "\t+ [iteration 0086] Loss: 0.0000, Best loss: 0.0000\n",
      "    -> Early stop at epoch 86\n",
      "----Running time:  0.38970375061035156\n",
      "+ Prepare model Bayesian_LogisticRegression with label eventdeath\n",
      "    Training with minibacth  0\n",
      "\t+ [iteration 0001] Loss: 0.0043, Best loss: 0.0043\n",
      "\t+ [iteration 0052] Loss: 0.0021, Best loss: 0.0021\n",
      "    -> Early stop at epoch 52\n",
      "    Training with minibacth  1\n",
      "\t+ [iteration 0001] Loss: 0.0049, Best loss: 0.0049\n",
      "\t+ [iteration 0051] Loss: 0.0032, Best loss: 0.0032\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  2\n",
      "\t+ [iteration 0001] Loss: 0.0039, Best loss: 0.0039\n",
      "\t+ [iteration 0051] Loss: 0.0021, Best loss: 0.0021\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  3\n",
      "\t+ [iteration 0001] Loss: 0.0055, Best loss: 0.0055\n",
      "\t+ [iteration 0051] Loss: 0.0026, Best loss: 0.0026\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  4\n",
      "\t+ [iteration 0001] Loss: 0.0045, Best loss: 0.0045\n",
      "\t+ [iteration 0051] Loss: 0.0023, Best loss: 0.0023\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  5\n",
      "\t+ [iteration 0001] Loss: 0.0198, Best loss: 0.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-27 08:36:06,643]\u001b[0m Trial 1 finished with value: -0.46153846153846156 and parameters: {'binarize.method': 'gettop', 'pca.outputdim': 10, 'scoring.impact': False, 'scoring.scale': False, 'scoring.log': False, 'LogisticRegression.learning_rate': 0.0085, 'Bayesian_LogisticRegression.learning_rate': 0.0005}. Best is trial 1 with value: -0.46153846153846156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t+ [iteration 0089] Loss: 0.0000, Best loss: 0.0000\n",
      "    -> Early stop at epoch 89\n",
      "----Running time:  0.3276519775390625\n",
      "Prepare contextual data\n",
      "Prepare data for models\n",
      "Train ensemble Ensemble\n",
      "+ Prepare model LogisticRegression with label eventdeath\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training with minibacth  0\n",
      "\t+ [iteration 0001] Loss: 0.0209, Best loss: 0.0209\n",
      "\t+ [iteration 0056] Loss: 0.0077, Best loss: 0.0077\n",
      "    -> Early stop at epoch 56\n",
      "    Training with minibacth  1\n",
      "\t+ [iteration 0001] Loss: 0.0141, Best loss: 0.0141\n",
      "\t+ [iteration 0051] Loss: 0.0104, Best loss: 0.0104\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  2\n",
      "\t+ [iteration 0001] Loss: 0.0119, Best loss: 0.0119\n",
      "\t+ [iteration 0051] Loss: 0.0073, Best loss: 0.0073\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  3\n",
      "\t+ [iteration 0001] Loss: 0.0162, Best loss: 0.0162\n",
      "\t+ [iteration 0051] Loss: 0.0087, Best loss: 0.0087\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  4\n",
      "\t+ [iteration 0001] Loss: 0.0130, Best loss: 0.0130\n",
      "\t+ [iteration 0051] Loss: 0.0077, Best loss: 0.0077\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  5\n",
      "\t+ [iteration 0001] Loss: 0.0804, Best loss: 0.0804\n",
      "\t+ [iteration 0088] Loss: 0.0003, Best loss: 0.0003\n",
      "    -> Early stop at epoch 88\n",
      "----Running time:  0.6259095668792725\n",
      "+ Prepare model Bayesian_LogisticRegression with label eventdeath\n",
      "    Training with minibacth  0\n",
      "\t+ [iteration 0001] Loss: 0.0056, Best loss: 0.0056\n",
      "\t+ [iteration 0052] Loss: 0.0051, Best loss: 0.0050\n",
      "    -> Early stop at epoch 52\n",
      "    Training with minibacth  1\n",
      "\t+ [iteration 0001] Loss: 0.0079, Best loss: 0.0079\n",
      "\t+ [iteration 0051] Loss: 0.0079, Best loss: 0.0079\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  2\n",
      "\t+ [iteration 0001] Loss: 0.0079, Best loss: 0.0079\n",
      "\t+ [iteration 0051] Loss: 0.0079, Best loss: 0.0079\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  3\n",
      "\t+ [iteration 0001] Loss: 0.0074, Best loss: 0.0074\n",
      "\t+ [iteration 0051] Loss: 0.0074, Best loss: 0.0074\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  4\n",
      "\t+ [iteration 0001] Loss: 0.0074, Best loss: 0.0074\n",
      "\t+ [iteration 0051] Loss: 0.0074, Best loss: 0.0074\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  5\n",
      "\t+ [iteration 0001] Loss: 0.0000, Best loss: 0.0000\n",
      "\t+ [iteration 0051] Loss: 0.0000, Best loss: 0.0000\n",
      "    -> Early stop at epoch 51\n",
      "----Running time:  0.3913142681121826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-27 08:36:19,719]\u001b[0m Trial 2 finished with value: -0.38461538461538464 and parameters: {'binarize.method': 'gettop', 'pca.outputdim': 100, 'scoring.impact': False, 'scoring.scale': True, 'scoring.log': False, 'LogisticRegression.learning_rate': 0.0005, 'Bayesian_LogisticRegression.learning_rate': 0.007000000000000001}. Best is trial 1 with value: -0.46153846153846156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare contextual data\n",
      "Prepare data for models\n",
      "Train ensemble Ensemble\n",
      "+ Prepare model LogisticRegression with label eventdeath\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training with minibacth  0\n",
      "\t+ [iteration 0001] Loss: 0.0162, Best loss: 0.0162\n",
      "\t+ [iteration 0100] Loss: 0.0006, Best loss: 0.0006\n",
      "\t+ [iteration 0117] Loss: 0.0005, Best loss: 0.0005\n",
      "    -> Early stop at epoch 117\n",
      "    Training with minibacth  1\n",
      "\t+ [iteration 0001] Loss: 0.0244, Best loss: 0.0244\n",
      "\t+ [iteration 0097] Loss: 0.0005, Best loss: 0.0005\n",
      "    -> Early stop at epoch 97\n",
      "    Training with minibacth  2\n",
      "\t+ [iteration 0001] Loss: 0.0158, Best loss: 0.0158\n",
      "\t+ [iteration 0100] Loss: 0.0002, Best loss: 0.0002\n",
      "\t+ [iteration 0101] Loss: 0.0002, Best loss: 0.0002\n",
      "    -> Early stop at epoch 101\n",
      "    Training with minibacth  3\n",
      "\t+ [iteration 0001] Loss: 0.0232, Best loss: 0.0232\n",
      "\t+ [iteration 0100] Loss: 0.0003, Best loss: 0.0003\n",
      "\t+ [iteration 0105] Loss: 0.0003, Best loss: 0.0003\n",
      "    -> Early stop at epoch 105\n",
      "    Training with minibacth  4\n",
      "\t+ [iteration 0001] Loss: 0.0181, Best loss: 0.0181\n",
      "\t+ [iteration 0100] Loss: 0.0002, Best loss: 0.0002\n",
      "\t+ [iteration 0101] Loss: 0.0002, Best loss: 0.0002\n",
      "    -> Early stop at epoch 101\n",
      "    Training with minibacth  5\n",
      "\t+ [iteration 0001] Loss: 0.0021, Best loss: 0.0021\n",
      "\t+ [iteration 0088] Loss: 0.0000, Best loss: 0.0000\n",
      "    -> Early stop at epoch 88\n",
      "----Running time:  1.2410309314727783\n",
      "+ Prepare model Bayesian_LogisticRegression with label eventdeath\n",
      "    Training with minibacth  0\n",
      "\t+ [iteration 0001] Loss: 0.0060, Best loss: 0.0060\n",
      "\t+ [iteration 0071] Loss: 0.0018, Best loss: 0.0018\n",
      "    -> Early stop at epoch 71\n",
      "    Training with minibacth  1\n",
      "\t+ [iteration 0001] Loss: 0.0052, Best loss: 0.0052\n",
      "\t+ [iteration 0051] Loss: 0.0028, Best loss: 0.0028\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  2\n",
      "\t+ [iteration 0001] Loss: 0.0039, Best loss: 0.0039\n",
      "\t+ [iteration 0051] Loss: 0.0017, Best loss: 0.0017\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  3\n",
      "\t+ [iteration 0001] Loss: 0.0057, Best loss: 0.0057\n",
      "\t+ [iteration 0075] Loss: 0.0016, Best loss: 0.0016\n",
      "    -> Early stop at epoch 75\n",
      "    Training with minibacth  4\n",
      "\t+ [iteration 0001] Loss: 0.0043, Best loss: 0.0043\n",
      "\t+ [iteration 0051] Loss: 0.0017, Best loss: 0.0017\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  5\n",
      "\t+ [iteration 0001] Loss: 0.0093, Best loss: 0.0093\n",
      "\t+ [iteration 0088] Loss: 0.0000, Best loss: 0.0000\n",
      "    -> Early stop at epoch 88\n",
      "----Running time:  0.3958861827850342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-27 08:36:33,314]\u001b[0m Trial 3 finished with value: -0.38461538461538464 and parameters: {'binarize.method': 'gettop', 'pca.outputdim': 10, 'scoring.impact': False, 'scoring.scale': True, 'scoring.log': True, 'LogisticRegression.learning_rate': 0.008, 'Bayesian_LogisticRegression.learning_rate': 0.0005}. Best is trial 1 with value: -0.46153846153846156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare contextual data\n",
      "Prepare data for models\n",
      "Train ensemble Ensemble\n",
      "+ Prepare model LogisticRegression with label eventdeath\n",
      "    Training with minibacth  0\n",
      "\t+ [iteration 0001] Loss: 0.0173, Best loss: 0.0173\n",
      "\t+ [iteration 0100] Loss: 0.0013, Best loss: 0.0013\n",
      "\t+ [iteration 0112] Loss: 0.0011, Best loss: 0.0011\n",
      "    -> Early stop at epoch 112\n",
      "    Training with minibacth  1\n",
      "\t+ [iteration 0001] Loss: 0.0211, Best loss: 0.0211\n",
      "\t+ [iteration 0100] Loss: 0.0012, Best loss: 0.0012\n",
      "\t+ [iteration 0103] Loss: 0.0011, Best loss: 0.0011\n",
      "    -> Early stop at epoch 103\n",
      "    Training with minibacth  2\n",
      "\t+ [iteration 0001] Loss: 0.0137, Best loss: 0.0137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t+ [iteration 0100] Loss: 0.0004, Best loss: 0.0004\n",
      "\t+ [iteration 0105] Loss: 0.0004, Best loss: 0.0004\n",
      "    -> Early stop at epoch 105\n",
      "    Training with minibacth  3\n",
      "\t+ [iteration 0001] Loss: 0.0199, Best loss: 0.0199\n",
      "\t+ [iteration 0097] Loss: 0.0005, Best loss: 0.0005\n",
      "    -> Early stop at epoch 97\n",
      "    Training with minibacth  4\n",
      "\t+ [iteration 0001] Loss: 0.0153, Best loss: 0.0153\n",
      "\t+ [iteration 0098] Loss: 0.0004, Best loss: 0.0004\n",
      "    -> Early stop at epoch 98\n",
      "    Training with minibacth  5\n",
      "\t+ [iteration 0001] Loss: 0.0077, Best loss: 0.0077\n",
      "\t+ [iteration 0086] Loss: 0.0000, Best loss: 0.0000\n",
      "    -> Early stop at epoch 86\n",
      "----Running time:  0.40889453887939453\n",
      "+ Prepare model Bayesian_LogisticRegression with label eventdeath\n",
      "    Training with minibacth  0\n",
      "\t+ [iteration 0001] Loss: 0.0073, Best loss: 0.0073\n",
      "\t+ [iteration 0052] Loss: 0.0051, Best loss: 0.0051\n",
      "    -> Early stop at epoch 52\n",
      "    Training with minibacth  1\n",
      "\t+ [iteration 0001] Loss: 0.0079, Best loss: 0.0079\n",
      "\t+ [iteration 0051] Loss: 0.0079, Best loss: 0.0079\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  2\n",
      "\t+ [iteration 0001] Loss: 0.0079, Best loss: 0.0079\n",
      "\t+ [iteration 0051] Loss: 0.0079, Best loss: 0.0079\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  3\n",
      "\t+ [iteration 0001] Loss: 0.0074, Best loss: 0.0074\n",
      "\t+ [iteration 0051] Loss: 0.0074, Best loss: 0.0074\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  4\n",
      "\t+ [iteration 0001] Loss: 0.0074, Best loss: 0.0074\n",
      "\t+ [iteration 0051] Loss: 0.0074, Best loss: 0.0074\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  5\n",
      "\t+ [iteration 0001] Loss: 0.0000, Best loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "\u001b[32m[I 2021-04-27 08:36:47,308]\u001b[0m Trial 4 finished with value: -0.2222222222222222 and parameters: {'binarize.method': 'threshold', 'threshold.method': 'kmeans', 'pca.outputdim': 5, 'scoring.impact': False, 'scoring.scale': False, 'scoring.log': False, 'LogisticRegression.learning_rate': 0.01, 'Bayesian_LogisticRegression.learning_rate': 0.0085}. Best is trial 1 with value: -0.46153846153846156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t+ [iteration 0051] Loss: 0.0000, Best loss: 0.0000\n",
      "    -> Early stop at epoch 51\n",
      "----Running time:  0.29657769203186035\n",
      "Prepare contextual data\n",
      "Prepare data for models\n",
      "Train ensemble Ensemble\n",
      "+ Prepare model LogisticRegression with label eventdeath\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training with minibacth  0\n",
      "\t+ [iteration 0001] Loss: 0.0135, Best loss: 0.0135\n",
      "\t+ [iteration 0100] Loss: 0.0005, Best loss: 0.0005\n",
      "\t+ [iteration 0118] Loss: 0.0004, Best loss: 0.0004\n",
      "    -> Early stop at epoch 118\n",
      "    Training with minibacth  1\n",
      "\t+ [iteration 0001] Loss: 0.0253, Best loss: 0.0253\n",
      "\t+ [iteration 0100] Loss: 0.0004, Best loss: 0.0004\n",
      "\t+ [iteration 0100] Loss: 0.0004, Best loss: 0.0004\n",
      "    -> Early stop at epoch 100\n",
      "    Training with minibacth  2\n",
      "\t+ [iteration 0001] Loss: 0.0158, Best loss: 0.0158\n",
      "\t+ [iteration 0100] Loss: 0.0002, Best loss: 0.0002\n",
      "\t+ [iteration 0101] Loss: 0.0002, Best loss: 0.0002\n",
      "    -> Early stop at epoch 101\n",
      "    Training with minibacth  3\n",
      "\t+ [iteration 0001] Loss: 0.0237, Best loss: 0.0237\n",
      "\t+ [iteration 0100] Loss: 0.0002, Best loss: 0.0002\n",
      "\t+ [iteration 0105] Loss: 0.0002, Best loss: 0.0002\n",
      "    -> Early stop at epoch 105\n",
      "    Training with minibacth  4\n",
      "\t+ [iteration 0001] Loss: 0.0182, Best loss: 0.0182\n",
      "\t+ [iteration 0100] Loss: 0.0002, Best loss: 0.0002\n",
      "\t+ [iteration 0101] Loss: 0.0002, Best loss: 0.0002\n",
      "    -> Early stop at epoch 101\n",
      "    Training with minibacth  5\n",
      "\t+ [iteration 0001] Loss: 0.0020, Best loss: 0.0020\n",
      "\t+ [iteration 0089] Loss: 0.0000, Best loss: 0.0000\n",
      "    -> Early stop at epoch 89\n",
      "----Running time:  1.2689571380615234\n",
      "+ Prepare model Bayesian_LogisticRegression with label eventdeath\n",
      "    Training with minibacth  0\n",
      "\t+ [iteration 0001] Loss: 0.0059, Best loss: 0.0059\n",
      "\t+ [iteration 0100] Loss: 0.0002, Best loss: 0.0002\n",
      "\t+ [iteration 0155] Loss: 0.0001, Best loss: 0.0001\n",
      "    -> Early stop at epoch 155\n",
      "    Training with minibacth  1\n",
      "\t+ [iteration 0001] Loss: 0.0064, Best loss: 0.0064\n",
      "\t+ [iteration 0084] Loss: 0.0006, Best loss: 0.0006\n",
      "    -> Early stop at epoch 84\n",
      "    Training with minibacth  2\n",
      "\t+ [iteration 0001] Loss: 0.0035, Best loss: 0.0035\n",
      "\t+ [iteration 0100] Loss: 0.0000, Best loss: 0.0000\n",
      "\t+ [iteration 0108] Loss: 0.0000, Best loss: 0.0000\n",
      "    -> Early stop at epoch 108\n",
      "    Training with minibacth  3\n",
      "\t+ [iteration 0001] Loss: 0.0055, Best loss: 0.0055\n",
      "\t+ [iteration 0100] Loss: 0.0001, Best loss: 0.0001\n",
      "\t+ [iteration 0114] Loss: 0.0001, Best loss: 0.0001\n",
      "    -> Early stop at epoch 114\n",
      "    Training with minibacth  4\n",
      "\t+ [iteration 0001] Loss: 0.0044, Best loss: 0.0044\n",
      "\t+ [iteration 0100] Loss: 0.0000, Best loss: 0.0000\n",
      "\t+ [iteration 0112] Loss: 0.0000, Best loss: 0.0000\n",
      "    -> Early stop at epoch 112\n",
      "    Training with minibacth  5\n",
      "\t+ [iteration 0001] Loss: 0.0002, Best loss: 0.0002\n",
      "\t+ [iteration 0092] Loss: 0.0000, Best loss: 0.0000\n",
      "    -> Early stop at epoch 92\n",
      "----Running time:  0.6641018390655518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-27 08:37:00,565]\u001b[0m Trial 5 finished with value: -0.38461538461538464 and parameters: {'binarize.method': 'gettop', 'pca.outputdim': 100, 'scoring.impact': False, 'scoring.scale': True, 'scoring.log': True, 'LogisticRegression.learning_rate': 0.009500000000000001, 'Bayesian_LogisticRegression.learning_rate': 0.003}. Best is trial 1 with value: -0.46153846153846156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare contextual data\n",
      "Prepare data for models\n",
      "Train ensemble Ensemble\n",
      "+ Prepare model LogisticRegression with label eventdeath\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training with minibacth  0\n",
      "\t+ [iteration 0001] Loss: 0.0168, Best loss: 0.0168\n",
      "\t+ [iteration 0078] Loss: 0.0034, Best loss: 0.0034\n",
      "    -> Early stop at epoch 78\n",
      "    Training with minibacth  1\n",
      "\t+ [iteration 0001] Loss: 0.0165, Best loss: 0.0165\n",
      "\t+ [iteration 0068] Loss: 0.0047, Best loss: 0.0047\n",
      "    -> Early stop at epoch 68\n",
      "    Training with minibacth  2\n",
      "\t+ [iteration 0001] Loss: 0.0120, Best loss: 0.0120\n",
      "\t+ [iteration 0096] Loss: 0.0013, Best loss: 0.0013\n",
      "    -> Early stop at epoch 96\n",
      "    Training with minibacth  3\n",
      "\t+ [iteration 0001] Loss: 0.0178, Best loss: 0.0178\n",
      "\t+ [iteration 0088] Loss: 0.0019, Best loss: 0.0019\n",
      "    -> Early stop at epoch 88\n",
      "    Training with minibacth  4\n",
      "\t+ [iteration 0001] Loss: 0.0145, Best loss: 0.0145\n",
      "\t+ [iteration 0090] Loss: 0.0015, Best loss: 0.0015\n",
      "    -> Early stop at epoch 90\n",
      "    Training with minibacth  5\n",
      "\t+ [iteration 0001] Loss: 0.0218, Best loss: 0.0218\n",
      "\t+ [iteration 0087] Loss: 0.0000, Best loss: 0.0000\n",
      "    -> Early stop at epoch 87\n",
      "----Running time:  0.7143101692199707\n",
      "+ Prepare model Bayesian_LogisticRegression with label eventdeath\n",
      "    Training with minibacth  0\n",
      "\t+ [iteration 0001] Loss: 0.0061, Best loss: 0.0061\n",
      "\t+ [iteration 0052] Loss: 0.0051, Best loss: 0.0051\n",
      "    -> Early stop at epoch 52\n",
      "    Training with minibacth  1\n",
      "\t+ [iteration 0001] Loss: 0.0079, Best loss: 0.0079\n",
      "\t+ [iteration 0051] Loss: 0.0079, Best loss: 0.0079\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  2\n",
      "\t+ [iteration 0001] Loss: 0.0079, Best loss: 0.0079\n",
      "\t+ [iteration 0051] Loss: 0.0079, Best loss: 0.0079\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  3\n",
      "\t+ [iteration 0001] Loss: 0.0074, Best loss: 0.0074\n",
      "\t+ [iteration 0051] Loss: 0.0074, Best loss: 0.0074\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  4\n",
      "\t+ [iteration 0001] Loss: 0.0074, Best loss: 0.0074\n",
      "\t+ [iteration 0051] Loss: 0.0074, Best loss: 0.0074\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  5\n",
      "\t+ [iteration 0001] Loss: 0.0000, Best loss: 0.0000\n",
      "\t+ [iteration 0051] Loss: 0.0000, Best loss: 0.0000\n",
      "    -> Early stop at epoch 51\n",
      "----Running time:  0.29972386360168457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-27 08:37:12,893]\u001b[0m Trial 6 finished with value: -0.3076923076923077 and parameters: {'binarize.method': 'gettop', 'pca.outputdim': None, 'scoring.impact': False, 'scoring.scale': False, 'scoring.log': True, 'LogisticRegression.learning_rate': 0.003, 'Bayesian_LogisticRegression.learning_rate': 0.0085}. Best is trial 1 with value: -0.46153846153846156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare contextual data\n",
      "Prepare data for models\n",
      "Train ensemble Ensemble\n",
      "+ Prepare model LogisticRegression with label eventdeath\n",
      "    Training with minibacth  0\n",
      "\t+ [iteration 0001] Loss: 0.0159, Best loss: 0.0159\n",
      "\t+ [iteration 0100] Loss: 0.0015, Best loss: 0.0015\n",
      "\t+ [iteration 0110] Loss: 0.0013, Best loss: 0.0013\n",
      "    -> Early stop at epoch 110\n",
      "    Training with minibacth  1\n",
      "\t+ [iteration 0001] Loss: 0.0206, Best loss: 0.0206\n",
      "\t+ [iteration 0100] Loss: 0.0014, Best loss: 0.0014\n",
      "\t+ [iteration 0102] Loss: 0.0013, Best loss: 0.0013\n",
      "    -> Early stop at epoch 102\n",
      "    Training with minibacth  2\n",
      "\t+ [iteration 0001] Loss: 0.0135, Best loss: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t+ [iteration 0100] Loss: 0.0005, Best loss: 0.0005\n",
      "\t+ [iteration 0102] Loss: 0.0005, Best loss: 0.0005\n",
      "    -> Early stop at epoch 102\n",
      "    Training with minibacth  3\n",
      "\t+ [iteration 0001] Loss: 0.0193, Best loss: 0.0193\n",
      "\t+ [iteration 0098] Loss: 0.0006, Best loss: 0.0006\n",
      "    -> Early stop at epoch 98\n",
      "    Training with minibacth  4\n",
      "\t+ [iteration 0001] Loss: 0.0152, Best loss: 0.0152\n",
      "\t+ [iteration 0096] Loss: 0.0005, Best loss: 0.0005\n",
      "    -> Early stop at epoch 96\n",
      "    Training with minibacth  5\n",
      "\t+ [iteration 0001] Loss: 0.0084, Best loss: 0.0084\n",
      "\t+ [iteration 0087] Loss: 0.0000, Best loss: 0.0000\n",
      "    -> Early stop at epoch 87\n",
      "----Running time:  0.37375497817993164\n",
      "+ Prepare model Bayesian_LogisticRegression with label eventdeath\n",
      "    Training with minibacth  0\n",
      "\t+ [iteration 0001] Loss: 0.0069, Best loss: 0.0069\n",
      "\t+ [iteration 0052] Loss: 0.0051, Best loss: 0.0051\n",
      "    -> Early stop at epoch 52\n",
      "    Training with minibacth  1\n",
      "\t+ [iteration 0001] Loss: 0.0079, Best loss: 0.0079\n",
      "\t+ [iteration 0051] Loss: 0.0079, Best loss: 0.0079\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  2\n",
      "\t+ [iteration 0001] Loss: 0.0079, Best loss: 0.0079\n",
      "\t+ [iteration 0051] Loss: 0.0079, Best loss: 0.0079\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  3\n",
      "\t+ [iteration 0001] Loss: 0.0074, Best loss: 0.0074\n",
      "\t+ [iteration 0051] Loss: 0.0074, Best loss: 0.0074\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  4\n",
      "\t+ [iteration 0001] Loss: 0.0074, Best loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-27 08:37:24,509]\u001b[0m Trial 7 finished with value: -0.3076923076923077 and parameters: {'binarize.method': 'gettop', 'pca.outputdim': 100, 'scoring.impact': False, 'scoring.scale': False, 'scoring.log': False, 'LogisticRegression.learning_rate': 0.009500000000000001, 'Bayesian_LogisticRegression.learning_rate': 0.009500000000000001}. Best is trial 1 with value: -0.46153846153846156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t+ [iteration 0051] Loss: 0.0074, Best loss: 0.0074\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  5\n",
      "\t+ [iteration 0001] Loss: 0.0000, Best loss: 0.0000\n",
      "\t+ [iteration 0051] Loss: 0.0000, Best loss: 0.0000\n",
      "    -> Early stop at epoch 51\n",
      "----Running time:  0.3197803497314453\n",
      "Prepare contextual data\n",
      "Prepare data for models\n",
      "Train ensemble Ensemble\n",
      "+ Prepare model LogisticRegression with label eventdeath\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training with minibacth  0\n",
      "\t+ [iteration 0001] Loss: 0.0207, Best loss: 0.0207\n",
      "\t+ [iteration 0082] Loss: 0.0037, Best loss: 0.0037\n",
      "    -> Early stop at epoch 82\n",
      "    Training with minibacth  1\n",
      "\t+ [iteration 0001] Loss: 0.0162, Best loss: 0.0162\n",
      "\t+ [iteration 0066] Loss: 0.0053, Best loss: 0.0053\n",
      "    -> Early stop at epoch 66\n",
      "    Training with minibacth  2\n",
      "\t+ [iteration 0001] Loss: 0.0119, Best loss: 0.0119\n",
      "\t+ [iteration 0095] Loss: 0.0016, Best loss: 0.0016\n",
      "    -> Early stop at epoch 95\n",
      "    Training with minibacth  3\n",
      "\t+ [iteration 0001] Loss: 0.0173, Best loss: 0.0173\n",
      "\t+ [iteration 0089] Loss: 0.0021, Best loss: 0.0021\n",
      "    -> Early stop at epoch 89\n",
      "    Training with minibacth  4\n",
      "\t+ [iteration 0001] Loss: 0.0143, Best loss: 0.0143\n",
      "\t+ [iteration 0088] Loss: 0.0017, Best loss: 0.0017\n",
      "    -> Early stop at epoch 88\n",
      "    Training with minibacth  5\n",
      "\t+ [iteration 0001] Loss: 0.0282, Best loss: 0.0282\n",
      "\t+ [iteration 0087] Loss: 0.0000, Best loss: 0.0000\n",
      "    -> Early stop at epoch 87\n",
      "----Running time:  0.7362878322601318\n",
      "+ Prepare model Bayesian_LogisticRegression with label eventdeath\n",
      "    Training with minibacth  0\n",
      "\t+ [iteration 0001] Loss: 0.0058, Best loss: 0.0058\n",
      "\t+ [iteration 0052] Loss: 0.0051, Best loss: 0.0049\n",
      "    -> Early stop at epoch 52\n",
      "    Training with minibacth  1\n",
      "\t+ [iteration 0001] Loss: 0.0079, Best loss: 0.0079\n",
      "\t+ [iteration 0051] Loss: 0.0079, Best loss: 0.0079\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  2\n",
      "\t+ [iteration 0001] Loss: 0.0079, Best loss: 0.0079\n",
      "\t+ [iteration 0051] Loss: 0.0079, Best loss: 0.0079\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  3\n",
      "\t+ [iteration 0001] Loss: 0.0074, Best loss: 0.0074\n",
      "\t+ [iteration 0051] Loss: 0.0074, Best loss: 0.0074\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  4\n",
      "\t+ [iteration 0001] Loss: 0.0074, Best loss: 0.0074\n",
      "\t+ [iteration 0051] Loss: 0.0074, Best loss: 0.0074\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  5\n",
      "\t+ [iteration 0001] Loss: 0.0000, Best loss: 0.0000\n",
      "\t+ [iteration 0051] Loss: 0.0000, Best loss: 0.0000\n",
      "    -> Early stop at epoch 51\n",
      "----Running time:  0.2985262870788574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-27 08:37:37,223]\u001b[0m Trial 8 finished with value: -0.3076923076923077 and parameters: {'binarize.method': 'gettop', 'pca.outputdim': 10, 'scoring.impact': False, 'scoring.scale': False, 'scoring.log': True, 'LogisticRegression.learning_rate': 0.003, 'Bayesian_LogisticRegression.learning_rate': 0.0055}. Best is trial 1 with value: -0.46153846153846156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare contextual data\n",
      "Prepare data for models\n",
      "Train ensemble Ensemble\n",
      "+ Prepare model LogisticRegression with label eventdeath\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/root/.local/share/virtualenvs/ds-CSRLTXzN/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training with minibacth  0\n",
      "\t+ [iteration 0001] Loss: 0.0191, Best loss: 0.0191\n",
      "\t+ [iteration 0100] Loss: 0.0007, Best loss: 0.0007\n",
      "\t+ [iteration 0114] Loss: 0.0006, Best loss: 0.0006\n",
      "    -> Early stop at epoch 114\n",
      "    Training with minibacth  1\n",
      "\t+ [iteration 0001] Loss: 0.0236, Best loss: 0.0236\n",
      "\t+ [iteration 0099] Loss: 0.0006, Best loss: 0.0006\n",
      "    -> Early stop at epoch 99\n",
      "    Training with minibacth  2\n",
      "\t+ [iteration 0001] Loss: 0.0152, Best loss: 0.0152\n",
      "\t+ [iteration 0100] Loss: 0.0002, Best loss: 0.0002\n",
      "\t+ [iteration 0101] Loss: 0.0002, Best loss: 0.0002\n",
      "    -> Early stop at epoch 101\n",
      "    Training with minibacth  3\n",
      "\t+ [iteration 0001] Loss: 0.0228, Best loss: 0.0228\n",
      "\t+ [iteration 0100] Loss: 0.0003, Best loss: 0.0003\n",
      "\t+ [iteration 0101] Loss: 0.0003, Best loss: 0.0003\n",
      "    -> Early stop at epoch 101\n",
      "    Training with minibacth  4\n",
      "\t+ [iteration 0001] Loss: 0.0172, Best loss: 0.0172\n",
      "\t+ [iteration 0100] Loss: 0.0002, Best loss: 0.0002\n",
      "\t+ [iteration 0102] Loss: 0.0002, Best loss: 0.0002\n",
      "    -> Early stop at epoch 102\n",
      "    Training with minibacth  5\n",
      "\t+ [iteration 0001] Loss: 0.0023, Best loss: 0.0023\n",
      "\t+ [iteration 0089] Loss: 0.0000, Best loss: 0.0000\n",
      "    -> Early stop at epoch 89\n",
      "----Running time:  0.7801477909088135\n",
      "+ Prepare model Bayesian_LogisticRegression with label eventdeath\n",
      "    Training with minibacth  0\n",
      "\t+ [iteration 0001] Loss: 0.0063, Best loss: 0.0063\n",
      "\t+ [iteration 0052] Loss: 0.0051, Best loss: 0.0049\n",
      "    -> Early stop at epoch 52\n",
      "    Training with minibacth  1\n",
      "\t+ [iteration 0001] Loss: 0.0079, Best loss: 0.0079\n",
      "\t+ [iteration 0051] Loss: 0.0079, Best loss: 0.0079\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  2\n",
      "\t+ [iteration 0001] Loss: 0.0079, Best loss: 0.0079\n",
      "\t+ [iteration 0051] Loss: 0.0079, Best loss: 0.0079\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  3\n",
      "\t+ [iteration 0001] Loss: 0.0074, Best loss: 0.0074\n",
      "\t+ [iteration 0051] Loss: 0.0074, Best loss: 0.0074\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  4\n",
      "\t+ [iteration 0001] Loss: 0.0074, Best loss: 0.0074\n",
      "\t+ [iteration 0051] Loss: 0.0074, Best loss: 0.0074\n",
      "    -> Early stop at epoch 51\n",
      "    Training with minibacth  5\n",
      "\t+ [iteration 0001] Loss: 0.0000, Best loss: 0.0000\n",
      "\t+ [iteration 0051] Loss: 0.0000, Best loss: 0.0000\n",
      "    -> Early stop at epoch 51\n",
      "----Running time:  0.3081028461456299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-27 08:37:49,620]\u001b[0m Trial 9 finished with value: -0.38461538461538464 and parameters: {'binarize.method': 'gettop', 'pca.outputdim': None, 'scoring.impact': False, 'scoring.scale': True, 'scoring.log': False, 'LogisticRegression.learning_rate': 0.0075, 'Bayesian_LogisticRegression.learning_rate': 0.006}. Best is trial 1 with value: -0.46153846153846156.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from propensity_prediction.config.autotune.config_searcher import ConfigSearcher\n",
    "searcher = ConfigSearcher(task_package, classification_pipeline_space, run_epochs=500)\n",
    "searcher.search(n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89zHuSCBH_1q",
    "outputId": "6aef6a42-57f1-4d70-f66b-e1685664fb03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3076923076923077, 0.46153846153846156, 0.38461538461538464, 0.38461538461538464, 0.2222222222222222, 0.38461538461538464, 0.3076923076923077, 0.3076923076923077, 0.3076923076923077, 0.38461538461538464]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46153846153846156"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (searcher.list_results)\n",
    "searcher.best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_eiBUkqaIwcP",
    "outputId": "7d80e048-fd1d-464c-f407-af36d6627881"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binarize_config': {'method': 'gettop', 'para': {}},\n",
       " 'feature_engineering': [{'method': 'pca', 'para': {'outputdim': 5}},\n",
       "  {'method': 'scoring',\n",
       "   'para': {'impact': False, 'scale': False, 'log': False}}],\n",
       " 'model_config': [{'method': 'LogisticRegression',\n",
       "   'para': {'learning_rate': 0.007000000000000001, 'epochs': 1000}},\n",
       "  {'method': 'Bayesian_LogisticRegression',\n",
       "   'para': {'learning_rate': 0.006500000000000001, 'epochs': 1000}}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_config = searcher.best_config\n",
    "for i in range(len(best_config['model_config'])):\n",
    "    best_config['model_config'][i]['para']['epochs'] = 1000\n",
    "best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3LdpGDThI4TJ",
    "outputId": "367748a6-a2e6-44ff-d3f9-c59298397c57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare contextual data\n",
      "Prepare data for models\n",
      "Train ensemble Ensemble\n",
      "+ Prepare model LogisticRegression with label eventdeath\n",
      "    Training with minibacth  0\n",
      "\t+ [iteration 0001] Loss: 0.0363, Best loss: 0.0363\n",
      "\t+ [iteration 0160] Loss: 0.0008, Best loss: 0.0008\n",
      "    -> Early stop at epoch 160\n",
      "    Training with minibacth  1\n",
      "\t+ [iteration 0001] Loss: 0.0370, Best loss: 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/src-NVTF7jWz/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/root/.local/share/virtualenvs/src-NVTF7jWz/lib/python3.7/site-packages/pandas/core/indexing.py:376: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t+ [iteration 0154] Loss: 0.0003, Best loss: 0.0003\n",
      "    -> Early stop at epoch 154\n",
      "    Training with minibacth  2\n",
      "\t+ [iteration 0001] Loss: 0.0302, Best loss: 0.0302\n",
      "\t+ [iteration 0152] Loss: 0.0002, Best loss: 0.0002\n",
      "    -> Early stop at epoch 152\n",
      "    Training with minibacth  3\n",
      "\t+ [iteration 0001] Loss: 0.1017, Best loss: 0.1017\n",
      "\t+ [iteration 0164] Loss: 0.0007, Best loss: 0.0007\n",
      "    -> Early stop at epoch 164\n",
      "    Training with minibacth  4\n",
      "\t+ [iteration 0001] Loss: 0.0507, Best loss: 0.0507\n",
      "\t+ [iteration 0149] Loss: 0.0003, Best loss: 0.0003\n",
      "    -> Early stop at epoch 149\n",
      "    Training with minibacth  5\n",
      "\t+ [iteration 0001] Loss: 0.0299, Best loss: 0.0299\n",
      "\t+ [iteration 0155] Loss: 0.0002, Best loss: 0.0002\n",
      "    -> Early stop at epoch 155\n",
      "    Training with minibacth  6\n",
      "\t+ [iteration 0001] Loss: 0.0530, Best loss: 0.0530\n",
      "\t+ [iteration 0149] Loss: 0.0005, Best loss: 0.0005\n",
      "    -> Early stop at epoch 149\n",
      "    Training with minibacth  7\n",
      "\t+ [iteration 0001] Loss: 0.0450, Best loss: 0.0450\n",
      "\t+ [iteration 0158] Loss: 0.0002, Best loss: 0.0002\n",
      "    -> Early stop at epoch 158\n",
      "    Training with minibacth  8\n",
      "\t+ [iteration 0001] Loss: 0.0548, Best loss: 0.0548\n",
      "\t+ [iteration 0156] Loss: 0.0004, Best loss: 0.0004\n",
      "    -> Early stop at epoch 156\n",
      "    Training with minibacth  9\n",
      "\t+ [iteration 0001] Loss: 0.0446, Best loss: 0.0446\n",
      "\t+ [iteration 0152] Loss: 0.0003, Best loss: 0.0003\n",
      "    -> Early stop at epoch 152\n",
      "    Training with minibacth  10\n",
      "\t+ [iteration 0001] Loss: 0.0116, Best loss: 0.0116\n",
      "\t+ [iteration 0134] Loss: 0.0001, Best loss: 0.0001\n",
      "    -> Early stop at epoch 134\n",
      "----Running time:  1.043156623840332\n",
      "+ Prepare model Bayesian_LogisticRegression with label eventdeath\n",
      "    Training with minibacth  0\n",
      "\t+ [iteration 0001] Loss: 0.0127, Best loss: 0.0127\n",
      "\t+ [iteration 0102] Loss: 0.0125, Best loss: 0.0123\n",
      "    -> Early stop at epoch 102\n",
      "    Training with minibacth  1\n",
      "\t+ [iteration 0001] Loss: 0.0075, Best loss: 0.0075\n",
      "\t+ [iteration 0101] Loss: 0.0075, Best loss: 0.0075\n",
      "    -> Early stop at epoch 101\n",
      "    Training with minibacth  2\n",
      "\t+ [iteration 0001] Loss: 0.0075, Best loss: 0.0075\n",
      "\t+ [iteration 0101] Loss: 0.0075, Best loss: 0.0075\n",
      "    -> Early stop at epoch 101\n",
      "    Training with minibacth  3\n",
      "\t+ [iteration 0001] Loss: 0.0200, Best loss: 0.0200\n",
      "\t+ [iteration 0101] Loss: 0.0200, Best loss: 0.0200\n",
      "    -> Early stop at epoch 101\n",
      "    Training with minibacth  4\n",
      "\t+ [iteration 0001] Loss: 0.0175, Best loss: 0.0175\n",
      "\t+ [iteration 0101] Loss: 0.0175, Best loss: 0.0175\n",
      "    -> Early stop at epoch 101\n",
      "    Training with minibacth  5\n",
      "\t+ [iteration 0001] Loss: 0.0200, Best loss: 0.0200\n",
      "\t+ [iteration 0101] Loss: 0.0200, Best loss: 0.0200\n",
      "    -> Early stop at epoch 101\n",
      "    Training with minibacth  6\n",
      "\t+ [iteration 0001] Loss: 0.0200, Best loss: 0.0200\n",
      "\t+ [iteration 0101] Loss: 0.0200, Best loss: 0.0200\n",
      "    -> Early stop at epoch 101\n",
      "    Training with minibacth  7\n",
      "\t+ [iteration 0001] Loss: 0.0100, Best loss: 0.0100\n",
      "\t+ [iteration 0101] Loss: 0.0100, Best loss: 0.0100\n",
      "    -> Early stop at epoch 101\n",
      "    Training with minibacth  8\n",
      "\t+ [iteration 0001] Loss: 0.0175, Best loss: 0.0175\n",
      "\t+ [iteration 0101] Loss: 0.0175, Best loss: 0.0175\n",
      "    -> Early stop at epoch 101\n",
      "    Training with minibacth  9\n",
      "\t+ [iteration 0001] Loss: 0.0125, Best loss: 0.0125\n",
      "\t+ [iteration 0101] Loss: 0.0125, Best loss: 0.0125\n",
      "    -> Early stop at epoch 101\n",
      "    Training with minibacth  10\n",
      "\t+ [iteration 0001] Loss: 0.0204, Best loss: 0.0204\n",
      "\t+ [iteration 0101] Loss: 0.0204, Best loss: 0.0204\n",
      "    -> Early stop at epoch 101\n",
      "----Running time:  1.0039219856262207\n"
     ]
    }
   ],
   "source": [
    "eva_res, model = task_package.exec(best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lZkmPChER8M_",
    "outputId": "fe635436-0b1e-4244-9dc9-14b8490dfff9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.7014652014652014,\n",
       " 'binarize_methods': [{'method': 'gettop',\n",
       "   'list_results': [{'ntop': 7,\n",
       "     'results': {'accuracy': 0.7818181818181819,\n",
       "      'precision': 0.3076923076923077,\n",
       "      'recall': 0.5714285714285714,\n",
       "      'trueneg_rate': 0.9285714285714286,\n",
       "      'f1_score': 0.4}},\n",
       "    {'ntop': 13,\n",
       "     'results': {'accuracy': 0.7454545454545455,\n",
       "      'precision': 0.46153846153846156,\n",
       "      'recall': 0.46153846153846156,\n",
       "      'trueneg_rate': 0.8333333333333334,\n",
       "      'f1_score': 0.46153846153846156}},\n",
       "    {'ntop': 18,\n",
       "     'results': {'accuracy': 0.6545454545454545,\n",
       "      'precision': 0.46153846153846156,\n",
       "      'recall': 0.3333333333333333,\n",
       "      'trueneg_rate': 0.7142857142857143,\n",
       "      'f1_score': 0.3870967741935484}}]}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_res['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "7lBtSYx430MP"
   },
   "outputs": [],
   "source": [
    "config_path = 'propensity_prediction/config/detail_model_config/churnprediction_pipelineconfig.json'\n",
    "searcher.save_bestconfig(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "FOrRPCnosP9Q"
   ],
   "name": "Auto Tune - Churn Prediction",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
